{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1341ec9",
   "metadata": {},
   "source": [
    "# **JPM MLCOE TSRL 2026 Q1**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6e7d97",
   "metadata": {},
   "source": [
    "## 0. Global Configurations\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92bae7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from typing import Tuple\n",
    "\n",
    "\n",
    "pd.set_option('display.float_format', lambda v: f\"{v:,.2f}\")\n",
    "\n",
    "\n",
    "print('yfinance:', yf.__version__)\n",
    "print('pandas:', pd.__version__)\n",
    "print('tensorflow:', tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5489494f",
   "metadata": {},
   "source": [
    "## 1. Data Pipeline\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f2a2ad",
   "metadata": {},
   "source": [
    "### 1.1 Column Aliases and Identity Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3145050",
   "metadata": {},
   "outputs": [],
   "source": [
    "BS_ALIASES = {\n",
    "    \"Total Assets\": [\"Total Assets\"],\n",
    "    \"Total Liab\": [\"Total Liab\", \"Total Liabilities\", \"Total Liabilities Net Minority Interest\"],\n",
    "    \"Total Stockholder Equity\": [\"Total Stockholder Equity\", \"Total Equity Gross Minority Interest\", \"Stockholders Equity\"],\n",
    "}\n",
    "\n",
    "\n",
    "def canonicalize_bs(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    rename_map = {}\n",
    "\n",
    "    for canon, candidates in BS_ALIASES.items():\n",
    "        for c in candidates:\n",
    "\n",
    "            if c in df.columns:\n",
    "                rename_map[c] = canon\n",
    "                \n",
    "                break\n",
    "\n",
    "    return df.rename(columns = rename_map)\n",
    "\n",
    "\n",
    "def identity_residual(df: pd.DataFrame) -> pd.Series:\n",
    "\n",
    "    if \"Total Liab\" not in df.columns or \"Total Stockholder Equity\" not in df.columns:\n",
    "        df = canonicalize_bs(df)\n",
    "    \n",
    "    required = [\"Total Assets\", \"Total Liab\", \"Total Stockholder Equity\"]\n",
    "    missing = [c for c in required if c not in df]\n",
    "\n",
    "    if missing:\n",
    "        raise KeyError(f\"Missing columns: {missing}\")\n",
    "\n",
    "\n",
    "    return df[\"Total Assets\"] - (df[\"Total Liab\"] + df[\"Total Stockholder Equity\"])\n",
    "\n",
    "\n",
    "def summarize_identity(resid: pd.Series) -> pd.Series:\n",
    "\n",
    "    return pd.Series({\n",
    "        \"mean\": resid.mean(),\n",
    "        \"std\": resid.std(),\n",
    "        \"max_abs\": resid.abs().max(),\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2590c66",
   "metadata": {},
   "source": [
    "### 1.2 Load AAPL Data with Caching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe162e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path(\"..\").resolve() / \"data\"\n",
    "DATA_DIR.mkdir(parents = True, exist_ok = True)\n",
    "\n",
    "def _fetch_statements(tkr, freq: str):\n",
    "    bs = tkr.get_balance_sheet(freq = freq)\n",
    "    is_df = tkr.get_financials(freq = freq)\n",
    "\n",
    "    if bs is None or is_df is None:\n",
    "        return pd.DataFrame(), pd.DataFrame()\n",
    "\n",
    "    bs = bs.T.sort_index()\n",
    "    is_df = is_df.T.sort_index()\n",
    "\n",
    "    return bs, is_df\n",
    "\n",
    "\n",
    "def _load_cached(path: Path) -> pd.DataFrame:\n",
    "    return pd.read_csv(path, index_col = 0, parse_dates = True)\n",
    "\n",
    "\n",
    "def load_statements(ticker: str = \"AAPL\"):\n",
    "    bs_y_path = DATA_DIR / f\"{ticker.lower()}_balance_sheet_yearly.csv\"\n",
    "    is_y_path = DATA_DIR / f\"{ticker.lower()}_income_statement_yearly.csv\"\n",
    "    bs_q_path = DATA_DIR / f\"{ticker.lower()}_balance_sheet_quarterly.csv\"\n",
    "    is_q_path = DATA_DIR / f\"{ticker.lower()}_income_statement_quarterly.csv\"\n",
    "\n",
    "    bs_y = pd.DataFrame()\n",
    "    is_y = pd.DataFrame()\n",
    "    bs_q = pd.DataFrame()\n",
    "    is_q = pd.DataFrame()\n",
    "\n",
    "    if bs_y_path.exists() and is_y_path.exists():\n",
    "        bs_y = _load_cached(bs_y_path)\n",
    "        is_y = _load_cached(is_y_path)\n",
    "\n",
    "    if bs_q_path.exists() and is_q_path.exists():\n",
    "        bs_q = _load_cached(bs_q_path)\n",
    "        is_q = _load_cached(is_q_path)\n",
    "\n",
    "    if bs_y.empty or is_y.empty or bs_q.empty or is_q.empty:\n",
    "        tkr = yf.Ticker(ticker)\n",
    "\n",
    "        if bs_y.empty or is_y.empty:\n",
    "            bs_y, is_y = _fetch_statements(tkr, \"yearly\")\n",
    "            if not bs_y.empty and not is_y.empty:\n",
    "                bs_y.to_csv(bs_y_path)\n",
    "                is_y.to_csv(is_y_path)\n",
    "\n",
    "        if bs_q.empty or is_q.empty:\n",
    "            bs_q, is_q = _fetch_statements(tkr, \"quarterly\")\n",
    "            if not bs_q.empty and not is_q.empty:\n",
    "                bs_q.to_csv(bs_q_path)\n",
    "                is_q.to_csv(is_q_path)\n",
    "\n",
    "    freq = \"quarterly\"\n",
    "    if bs_q.empty or is_q.empty or bs_y.shape[0] >= bs_q.shape[0]:\n",
    "        freq = \"yearly\"\n",
    "\n",
    "    if freq == \"quarterly\":\n",
    "        bs = bs_q\n",
    "        is_df = is_q\n",
    "    else:\n",
    "        bs = bs_y\n",
    "        is_df = is_y\n",
    "\n",
    "    if bs.empty or is_df.empty:\n",
    "        raise RuntimeError(f\"Failed to fetch statements for {ticker}\")\n",
    "\n",
    "    bs = canonicalize_bs(bs)\n",
    "\n",
    "    return bs, is_df, freq\n",
    "\n",
    "\n",
    "bs, is_df, stmt_freq = load_statements(\"AAPL\")\n",
    "\n",
    "\n",
    "print(\"Statement frequency:\", stmt_freq)\n",
    "print(\"Balance sheet shape:\", bs.shape)\n",
    "print(\"Income statement shape:\", is_df.shape)\n",
    "print(\"Identity residual stats:\", summarize_identity(identity_residual(bs)))\n",
    "bs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f580ccd",
   "metadata": {},
   "source": [
    "### 1.3 Dataset Assembly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8aef296",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _pick(df: pd.DataFrame, options):\n",
    "\n",
    "    for c in options:\n",
    "        if c in df.columns:\n",
    "            return df[c]\n",
    "\n",
    "    raise KeyError(f'Missing columns: {options}')\n",
    "\n",
    "\n",
    "def compute_features(\n",
    "    bs: pd.DataFrame,\n",
    "    is_df: pd.DataFrame,\n",
    "    days: float = 365.0,\n",
    "    growth_periods: int = 1\n",
    ") -> pd.DataFrame:\n",
    "\n",
    "    rev = _pick(is_df, ['Total Revenue', 'Operating Revenue'])\n",
    "    cogs = _pick(is_df, ['Cost Of Revenue', 'Cost of Revenue'])\n",
    "    op_inc = _pick(is_df, ['Operating Income'])\n",
    "    net_inc = _pick(is_df, ['Net Income'])\n",
    "    ar = _pick(bs, ['Accounts Receivable'])\n",
    "    ap = _pick(bs, ['Accounts Payable'])\n",
    "    inv = _pick(bs, ['Inventory'])\n",
    "\n",
    "    feats = pd.DataFrame(index = bs.index)\n",
    "\n",
    "    sales_per_day = rev / days\n",
    "    cogs_per_day = cogs / days\n",
    "\n",
    "    feats['dso'] = ar / sales_per_day\n",
    "    feats['dpo'] = ap / cogs_per_day\n",
    "    feats['dih'] = inv / cogs_per_day\n",
    "    feats['gross_margin'] = (rev - cogs) / rev\n",
    "    feats['op_margin'] = op_inc / rev\n",
    "    feats['net_margin'] = net_inc / rev\n",
    "    feats['rev_yoy'] = rev.pct_change(periods = growth_periods)\n",
    "    feats['cogs_yoy'] = cogs.pct_change(periods = growth_periods)\n",
    "    feats['netinc_yoy'] = net_inc.pct_change(periods = growth_periods)\n",
    "    feats['log_rev'] = np.log1p(rev)\n",
    "    feats['log_assets'] = np.log1p(_pick(bs, ['Total Assets']))\n",
    "    \n",
    "    feats = feats.replace([np.inf, -np.inf], np.nan)\n",
    "    feats = feats.sort_index().ffill().bfill()\n",
    "\n",
    "\n",
    "    return feats\n",
    "\n",
    "\n",
    "period_days = 365.0 if stmt_freq == 'yearly' else 90.0\n",
    "growth_periods = 1 if stmt_freq == 'yearly' else 4\n",
    "\n",
    "features = compute_features(bs, is_df, days = period_days, growth_periods = growth_periods)\n",
    "features.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c7aeaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_BS = ['Total Assets', 'Total Liab', 'Total Stockholder Equity']\n",
    "NET_INCOME_COL = 'Net Income'\n",
    "\n",
    "targets = bs[TARGET_BS].copy()\n",
    "net_income = _pick(is_df, ['Net Income']).rename(NET_INCOME_COL)\n",
    "net_income.index = targets.index\n",
    "\n",
    "dataset = features.join(targets, how = 'inner').join(net_income, how = 'inner')\n",
    "dataset = dataset.dropna()\n",
    "FEATURE_COLS = [c for c in dataset.columns if c not in TARGET_BS + [NET_INCOME_COL]]\n",
    "\n",
    "\n",
    "print('Dataset shape:', dataset.shape)\n",
    "print('Feature cols:', len(FEATURE_COLS), 'Target cols:', len(TARGET_BS) + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eff5de3",
   "metadata": {},
   "source": [
    "### 1.4 Scaling (z-score) for Stability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbb7c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_scaler = StandardScaler()\n",
    "bs_scaler = StandardScaler()\n",
    "earn_scaler = StandardScaler()\n",
    "prev_scaler = StandardScaler()\n",
    "\n",
    "X_feat_scaled = feat_scaler.fit_transform(X_feat)\n",
    "Y_bs_scaled = bs_scaler.fit_transform(Y_bs)\n",
    "Y_earn_scaled = earn_scaler.fit_transform(Y_earn)\n",
    "X_prev_scaled = prev_scaler.fit_transform(X_prev)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3badfb3a",
   "metadata": {},
   "source": [
    "### 1.5 Train/Val Split on Scaled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511f37a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = X_feat_scaled.shape[0]\n",
    "train_size = max(1, int(0.8 * n))\n",
    "\n",
    "X_train_feat = X_feat_scaled[:train_size]\n",
    "Y_train_bs = Y_bs_scaled[:train_size]\n",
    "Y_train_earn = Y_earn_scaled[:train_size]\n",
    "X_train_prev = X_prev_scaled[:train_size]\n",
    "\n",
    "X_val_feat = X_feat_scaled[train_size:] if train_size < n else X_feat_scaled[train_size - 1:]\n",
    "Y_val_bs = Y_bs_scaled[train_size:] if train_size < n else Y_bs_scaled[train_size - 1:]\n",
    "Y_val_earn = Y_earn_scaled[train_size:] if train_size < n else Y_earn_scaled[train_size - 1:]\n",
    "X_val_prev = X_prev_scaled[train_size:] if train_size < n else X_prev_scaled[train_size - 1:]\n",
    "\n",
    "\n",
    "print('Scaled train:', X_train_feat.shape, Y_train_bs.shape, Y_train_earn.shape)\n",
    "print('Scaled val:', X_val_feat.shape, Y_val_bs.shape, Y_val_earn.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d43e051",
   "metadata": {},
   "source": [
    "## 2. TensorFlow (Pareja/Pelaez Constrained)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bad65ce",
   "metadata": {},
   "source": [
    "## 2.1 TF Model with Algebraic Generator + Earnings Head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c449ad68",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlgebraicBS(keras.layers.Layer):\n",
    "\n",
    "    def __init__(self):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.hidden = keras.layers.Dense(64, activation = 'relu')\n",
    "        self.rev_head = keras.layers.Dense(1, activation = 'relu')\n",
    "        self.cogs_head = keras.layers.Dense(1, activation = 'relu')\n",
    "        self.drivers = keras.layers.Dense(5)\n",
    "        self.margin_head = keras.layers.Dense(1)\n",
    "        self.payout_head = keras.layers.Dense(1)\n",
    "        self.earn_head = keras.layers.Dense(1, name = 'net_income_head')\n",
    "\n",
    "\n",
    "    def call(self, inputs: Tuple[tf.Tensor, tf.Tensor]):\n",
    "\n",
    "        if not isinstance(inputs, (tuple, list)):\n",
    "            raise TypeError(\"inputs must be (features, prev_state)\")\n",
    "\n",
    "        features, prev_state = inputs\n",
    "        ar_prev, ap_prev, inv_prev, ppe_prev, liab_prev, equity_prev, re_prev, rev_prev = tf.split(prev_state, num_or_size_splits=8, axis=-1)\n",
    "        hidden = self.hidden(features)\n",
    "        rev_pred = self.rev_head(hidden)\n",
    "        cogs_pred = self.cogs_head(hidden)\n",
    "        drivers_raw = self.drivers(hidden)\n",
    "\n",
    "        dso = tf.nn.softplus(drivers_raw[:, 0:1])\n",
    "        dpo = tf.nn.softplus(drivers_raw[:, 1:2])\n",
    "        dih = tf.nn.softplus(drivers_raw[:, 2:3])\n",
    "        dep_rate = tf.nn.sigmoid(drivers_raw[:, 3:4]) * 0.2\n",
    "        capex_rate = tf.nn.sigmoid(drivers_raw[:, 4:5]) * 0.2\n",
    "        net_margin = tf.tanh(self.margin_head(hidden)) * 0.5\n",
    "        div_payout = tf.nn.sigmoid(self.payout_head(hidden))\n",
    "\n",
    "        sales_per_day = rev_pred / 365.0\n",
    "        cogs_per_day = cogs_pred / 365.0\n",
    "\n",
    "        ar_next = dso * sales_per_day\n",
    "        ap_next = dpo * cogs_per_day\n",
    "        inv_next = dih * cogs_per_day\n",
    "        dep = dep_rate * ppe_prev\n",
    "        capex = capex_rate * rev_pred\n",
    "        ppe_next = ppe_prev + capex - dep\n",
    "        net_income = net_margin * rev_pred\n",
    "        earn_pred = self.earn_head(hidden)\n",
    "        div = div_payout * net_income\n",
    "        re_next = re_prev + net_income - div\n",
    "\n",
    "        other_equity = tf.nn.relu(equity_prev - re_prev)\n",
    "\n",
    "        equity_next = re_next + other_equity\n",
    "\n",
    "        other_liab_prev = tf.nn.relu(liab_prev - ap_prev)\n",
    "        growth = tf.where(rev_prev > 0, rev_pred / rev_prev - 1.0, tf.zeros_like(rev_pred))\n",
    "\n",
    "        other_liab_next = other_liab_prev * (1.0 + growth)\n",
    "        liab_next = ap_next + other_liab_next\n",
    "        assets_wo_cash = ar_next + inv_next + ppe_next\n",
    "        cash_next = equity_next + liab_next - assets_wo_cash\n",
    "        assets_next = assets_wo_cash + cash_next\n",
    "        bs_out = tf.concat([assets_next, liab_next, equity_next], axis = -1)\n",
    "\n",
    "\n",
    "        return bs_out, earn_pred\n",
    "\n",
    "\n",
    "def build_pareja_model(feat_dim: int, state_dim: int = 8):\n",
    "\n",
    "    feat_in = keras.Input(shape = (feat_dim,), name = 'features')\n",
    "    state_in = keras.Input(shape = (state_dim,), name = 'prev_state')\n",
    "    bs_out, earn_out = AlgebraicBS()([feat_in, state_in])\n",
    "    \n",
    "    \n",
    "    return keras.Model([feat_in, state_in], [bs_out, earn_out], name = 'bs_pareja_style')\n",
    "\n",
    "\n",
    "pareja_model = build_pareja_model(feat_dim = X_feat_scaled.shape[1], state_dim = X_prev_scaled.shape[1])\n",
    "pareja_model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
