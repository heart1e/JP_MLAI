{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7145005c",
   "metadata": {},
   "source": [
    "# **JPM MLCOE TSRL 2026 Q1**\n",
    "---\n",
    "**Xinyu Chen**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc951d86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing missing packages: scikit-learn, tensorflow, tensorflow-probability, yfinance\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.4; however, version 25.3 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Environment bootstrap: install missing deps if needed.\n",
    "import sys\n",
    "import importlib.util\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "REQUIRED = [\n",
    "    (\"numpy\", \"numpy\"),\n",
    "    (\"pandas\", \"pandas\"),\n",
    "    (\"matplotlib\", \"matplotlib\"),\n",
    "    (\"scikit-learn\", \"sklearn\"),\n",
    "    (\"tensorflow\", \"tensorflow\"),\n",
    "    (\"tensorflow-probability\", \"tensorflow_probability\"),\n",
    "    (\"yfinance\", \"yfinance\"),\n",
    "]\n",
    "\n",
    "missing = [pip_name for pip_name, mod in REQUIRED if importlib.util.find_spec(mod) is None]\n",
    "if missing:\n",
    "    print(\"Installing missing packages: \" + \", \".join(missing))\n",
    "    try:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", *missing])\n",
    "    except Exception as exc:\n",
    "        raise RuntimeError(\"Package install failed. Please install manually: \" + \", \".join(missing)) from exc\n",
    "\n",
    "# Reduce TensorFlow log noise (must be set before importing tensorflow).\n",
    "os.environ.setdefault(\"TF_CPP_MIN_LOG_LEVEL\", \"2\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc71548f",
   "metadata": {},
   "source": [
    "## 0. Global Configurations\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd96e8b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-21T19:16:43.684526Z",
     "iopub.status.busy": "2026-01-21T19:16:43.684230Z",
     "iopub.status.idle": "2026-01-21T19:16:54.320141Z",
     "shell.execute_reply": "2026-01-21T19:16:54.319268Z"
    }
   },
   "outputs": [],
   "source": [
    "# Core dependencies for data ingestion, modeling, and evaluation.\n",
    "from pathlib import Path\n",
    "import json\n",
    "import re\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow_probability as tfp\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from typing import Tuple\n",
    "\n",
    "\n",
    "pd.set_option('display.float_format', lambda v: f\"{v:,.2f}\")\n",
    "\n",
    "\n",
    "print('yfinance:', yf.__version__)\n",
    "print('pandas:', pd.__version__)\n",
    "print('tensorflow:', tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b485ab37",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-21T19:16:54.322429Z",
     "iopub.status.busy": "2026-01-21T19:16:54.321782Z",
     "iopub.status.idle": "2026-01-21T19:16:54.327624Z",
     "shell.execute_reply": "2026-01-21T19:16:54.326877Z"
    }
   },
   "outputs": [],
   "source": [
    "# Fix RNG seeds for reproducibility across runs.\n",
    "CONFIG_DIR = Path('..').resolve() / 'config'\n",
    "with open(CONFIG_DIR / 'model_config.json', 'r', encoding = 'utf-8-sig') as f:\n",
    "    MODEL_CONFIG = json.load(f)\n",
    "\n",
    "SEED = int(MODEL_CONFIG['seed'])\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.keras.utils.set_random_seed(SEED)\n",
    "tf.config.experimental.enable_op_determinism()\n",
    "\n",
    "# Configure cache location and statement frequency.\n",
    "DATA_DIR = Path('..').resolve() / MODEL_CONFIG['data_dir']\n",
    "DATA_DIR.mkdir(parents = True, exist_ok = True)\n",
    "TARGET_FREQ = MODEL_CONFIG['target_freq']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc79b813",
   "metadata": {},
   "source": [
    "## 1. Data Pipeline\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39187390",
   "metadata": {},
   "source": [
    "### 1.1 Column Aliases and Identity Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4627ff0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-21T19:16:54.329964Z",
     "iopub.status.busy": "2026-01-21T19:16:54.329636Z",
     "iopub.status.idle": "2026-01-21T19:16:54.334784Z",
     "shell.execute_reply": "2026-01-21T19:16:54.333770Z"
    }
   },
   "outputs": [],
   "source": [
    "# Provider column aliases to canonical balance sheet names.\n",
    "BS_ALIASES = MODEL_CONFIG['bs_aliases']\n",
    "\n",
    "\n",
    "def canonicalize_bs(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Return a balance sheet with canonical column names.\"\"\"\n",
    "\n",
    "    rename_map = {}\n",
    "\n",
    "    for canon, candidates in BS_ALIASES.items():\n",
    "        for c in candidates:\n",
    "\n",
    "            if c in df.columns:\n",
    "                rename_map[c] = canon\n",
    "                \n",
    "                break\n",
    "\n",
    "\n",
    "    return df.rename(columns = rename_map)\n",
    "\n",
    "\n",
    "def identity_residual(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"Compute balance sheet identity residuals.\"\"\"\n",
    "\n",
    "    if \"Total Liabilities\" not in df.columns or \"Total Equity\" not in df.columns:\n",
    "        df = canonicalize_bs(df)\n",
    "    \n",
    "    required = [\"Total Assets\", \"Total Liabilities\", \"Total Equity\"]\n",
    "    missing = [c for c in required if c not in df]\n",
    "\n",
    "    if missing:\n",
    "\n",
    "        raise KeyError(f\"Missing columns: {missing}\")\n",
    "\n",
    "\n",
    "    return df[\"Total Assets\"] - (df[\"Total Liabilities\"] + df[\"Total Equity\"])\n",
    "\n",
    "\n",
    "def summarize_identity(resid: pd.Series) -> pd.Series:\n",
    "    \"\"\"Summarize residual statistics.\"\"\"\n",
    "\n",
    "    return pd.Series({\n",
    "\n",
    "        \"mean\": resid.mean(),\n",
    "        \"std\": resid.std(),\n",
    "        \"max_abs\": resid.abs().max(),\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34664233",
   "metadata": {},
   "source": [
    "### 1.2 Load Data with Caching\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef6df9c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-21T19:16:54.336751Z",
     "iopub.status.busy": "2026-01-21T19:16:54.336437Z",
     "iopub.status.idle": "2026-01-21T19:16:54.369343Z",
     "shell.execute_reply": "2026-01-21T19:16:54.368493Z"
    }
   },
   "outputs": [],
   "source": [
    "# Ticker normalization and cached statement loading utilities.\n",
    "SPECIAL_TICKERS = MODEL_CONFIG['special_tickers']\n",
    "FISCAL_YEAR_END_MONTHS_RAW = MODEL_CONFIG.get('fiscal_year_end_months', {})\n",
    "\n",
    "\n",
    "def normalize_ticker(raw: str) -> str:\n",
    "    \"\"\"Normalize tickers and apply project-specific mappings.\"\"\"\n",
    "\n",
    "    value = raw.strip()\n",
    "    upper = value.upper()\n",
    "\n",
    "    if upper in SPECIAL_TICKERS:\n",
    "\n",
    "        return SPECIAL_TICKERS[upper]\n",
    "\n",
    "    if re.fullmatch(r\"\\d+\", value):\n",
    "\n",
    "        return value.zfill(4) + \".HK\"\n",
    "\n",
    "\n",
    "    return upper\n",
    "\n",
    "\n",
    "FISCAL_YEAR_END_MONTHS = {\n",
    "    normalize_ticker(k): int(v) for k, v in FISCAL_YEAR_END_MONTHS_RAW.items()\n",
    "}\n",
    "\n",
    "\n",
    "def slugify(ticker: str) -> str:\n",
    "    \"\"\"Create a filesystem-friendly slug for a ticker.\"\"\"\n",
    "\n",
    "    return re.sub(r\"[^a-z0-9]+\", \"_\", ticker.lower()).strip(\"_\")\n",
    "\n",
    "\n",
    "def _fetch_statements(tkr, freq: str):\n",
    "    \"\"\"Fetch statements from Yahoo Finance for a ticker.\"\"\"\n",
    "\n",
    "    bs = tkr.get_balance_sheet(freq = freq)\n",
    "    is_df = tkr.get_financials(freq = freq)\n",
    "\n",
    "    if bs is None or is_df is None:\n",
    "\n",
    "        return pd.DataFrame(), pd.DataFrame()\n",
    "\n",
    "    bs = bs.T.sort_index()\n",
    "    is_df = is_df.T.sort_index()\n",
    "\n",
    "\n",
    "    return bs, is_df\n",
    "\n",
    "\n",
    "def _load_cached(path: Path) -> pd.DataFrame:\n",
    "    \"\"\"Load a cached statement CSV if available.\"\"\"\n",
    "\n",
    "    return pd.read_csv(path, index_col = 0, parse_dates = True)\n",
    "\n",
    "\n",
    "def load_statements(ticker: str, freq: str = TARGET_FREQ):\n",
    "    \"\"\"Load or fetch statements for a ticker and frequency.\"\"\"\n",
    "\n",
    "    ticker = normalize_ticker(ticker)\n",
    "    slug = slugify(ticker)\n",
    "    freq = freq.lower()\n",
    "\n",
    "    data_dir = DATA_DIR / freq\n",
    "    data_dir.mkdir(parents = True, exist_ok = True)\n",
    "\n",
    "    bs_path = data_dir / f\"{slug}_balance_sheet_{freq}.csv\"\n",
    "    is_path = data_dir / f\"{slug}_income_statement_{freq}.csv\"\n",
    "\n",
    "    # Prefer cached CSVs to reduce API calls.\n",
    "\n",
    "    if bs_path.exists() and is_path.exists():\n",
    "        bs = _load_cached(bs_path)\n",
    "        is_df = _load_cached(is_path)\n",
    "\n",
    "    else:\n",
    "        tkr = yf.Ticker(ticker)\n",
    "        bs, is_df = _fetch_statements(tkr, freq)\n",
    "\n",
    "        if not bs.empty and not is_df.empty:\n",
    "            bs.to_csv(bs_path)\n",
    "            is_df.to_csv(is_path)\n",
    "\n",
    "    if bs.empty or is_df.empty:\n",
    "\n",
    "        raise RuntimeError(f\"Failed to fetch statements for {ticker} ({freq})\")\n",
    "\n",
    "    bs = canonicalize_bs(bs)\n",
    "\n",
    "\n",
    "    return bs, is_df, freq\n",
    "\n",
    "\n",
    "TICKERS = MODEL_CONFIG['tickers']\n",
    "PRIMARY_TICKER = MODEL_CONFIG.get('primary_ticker', TICKERS[0])\n",
    "bs, is_df, stmt_freq = load_statements(PRIMARY_TICKER, freq = TARGET_FREQ)\n",
    "\n",
    "\n",
    "print(\"Loaded tickers:\", [normalize_ticker(t) for t in TICKERS])\n",
    "print(\"Statement frequency:\", stmt_freq)\n",
    "print(\"Balance sheet shape:\", bs.shape)\n",
    "print(\"Income statement shape:\", is_df.shape)\n",
    "print(\"Identity residual stats:\", summarize_identity(identity_residual(bs)))\n",
    "\n",
    "\n",
    "bs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d66b91",
   "metadata": {},
   "source": [
    "## 2. Features & Dataset\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55337ab4",
   "metadata": {},
   "source": [
    "### 2.1 Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61088a3e",
   "metadata": {},
   "source": [
    "#### 2.1.1 Derived Drivers (DSO/DPO/DIH, Margins, Growth, Logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a58281",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-21T19:16:54.371445Z",
     "iopub.status.busy": "2026-01-21T19:16:54.371058Z",
     "iopub.status.idle": "2026-01-21T19:16:54.396668Z",
     "shell.execute_reply": "2026-01-21T19:16:54.395613Z"
    }
   },
   "outputs": [],
   "source": [
    "# Feature engineering for working-capital efficiency and margins.\n",
    "def _pick(df: pd.DataFrame, options):\n",
    "    \"\"\"Pick the first available series from the provided options.\"\"\"\n",
    "\n",
    "    for c in options:\n",
    "\n",
    "        if c in df.columns:\n",
    "\n",
    "            return df[c]\n",
    "\n",
    "    raise KeyError(f'Missing columns: {options}')\n",
    "\n",
    "\n",
    "def _as_series(values, index) -> pd.Series:\n",
    "    \"\"\"Return values as a Series aligned to the provided index.\"\"\"\n",
    "\n",
    "    if isinstance(values, pd.Series):\n",
    "\n",
    "        return values.reindex(index)\n",
    "\n",
    "    return pd.Series(values, index = index)\n",
    "\n",
    "\n",
    "def fiscal_month_from_stmt(stmt_month: pd.Series, fy_end_month) -> pd.Series:\n",
    "    \"\"\"Map statement month to fiscal month number (1-12).\"\"\"\n",
    "\n",
    "    if fy_end_month is None:\n",
    "\n",
    "        return stmt_month.astype(float)\n",
    "\n",
    "    fy_end_series = _as_series(fy_end_month, stmt_month.index)\n",
    "    fy_end_series = fy_end_series.fillna(stmt_month)\n",
    "    fy_start = (fy_end_series % 12) + 1\n",
    "    fiscal_month = ((stmt_month - fy_start) % 12) + 1\n",
    "\n",
    "    return fiscal_month.astype(float)\n",
    "\n",
    "\n",
    "def fiscal_quarter_from_stmt(stmt_month: pd.Series, fy_end_month) -> pd.Series:\n",
    "    \"\"\"Map statement month to fiscal quarter number (1-4).\"\"\"\n",
    "\n",
    "    if fy_end_month is None:\n",
    "\n",
    "        return ((stmt_month - 1) // 3) + 1\n",
    "\n",
    "    fy_end_series = _as_series(fy_end_month, stmt_month.index)\n",
    "    fy_end_series = fy_end_series.fillna(stmt_month)\n",
    "    offset = (stmt_month - fy_end_series) % 12\n",
    "    fiscal_quarter = ((offset // 3 + 3) % 4) + 1\n",
    "\n",
    "    return fiscal_quarter.astype(int)\n",
    "\n",
    "\n",
    "def compute_features(\n",
    "    bs: pd.DataFrame,\n",
    "    is_df: pd.DataFrame,\n",
    "    ticker: str | None = None,\n",
    "    days: float = 365.0,\n",
    "    growth_periods: int = 1\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Compute financial ratios and growth features.\"\"\"\n",
    "\n",
    "    rev = _pick(is_df, ['Total Revenue', 'Operating Revenue', 'TotalRevenue', 'OperatingRevenue', 'Revenues'])\n",
    "    cogs = _pick(is_df, ['Cost Of Revenue', 'Cost of Revenue', 'CostOfRevenue', 'ReconciledCostOfRevenue'])\n",
    "    op_inc = _pick(is_df, ['Operating Income', 'OperatingIncome'])\n",
    "    net_inc = _pick(is_df, ['Net Income', 'NetIncome', 'NetIncomeFromContinuingOperationNetMinorityInterest'])\n",
    "    ar = _pick(bs, ['Accounts Receivable', 'AccountsReceivable'])\n",
    "    ap = _pick(bs, ['Accounts Payable', 'AccountsPayable'])\n",
    "    inv = _pick(bs, ['Inventory', 'Inventories'])\n",
    "\n",
    "    feats = pd.DataFrame(index = bs.index)\n",
    "\n",
    "    sales_per_day = rev / days\n",
    "    cogs_per_day = cogs / days\n",
    "\n",
    "    feats['dso'] = ar / sales_per_day\n",
    "    feats['dpo'] = ap / cogs_per_day\n",
    "    feats['dih'] = inv / cogs_per_day\n",
    "    feats['gross_margin'] = (rev - cogs) / rev\n",
    "    feats['op_margin'] = op_inc / rev\n",
    "    feats['net_margin'] = net_inc / rev\n",
    "    feats['rev_yoy'] = rev.pct_change(periods = growth_periods)\n",
    "    feats['cogs_yoy'] = cogs.pct_change(periods = growth_periods)\n",
    "    feats['netinc_yoy'] = net_inc.pct_change(periods = growth_periods)\n",
    "    feats['log_rev'] = np.log1p(rev)\n",
    "    feats['log_assets'] = np.log1p(_pick(bs, ['Total Assets', 'TotalAssets']))\n",
    "\n",
    "    # Fiscal seasonality aligned to fiscal year end month when configured.\n",
    "    stmt_month = pd.Series(pd.to_datetime(bs.index).month, index = bs.index)\n",
    "    fy_end_month = FISCAL_YEAR_END_MONTHS.get(ticker) if ticker else None\n",
    "    fiscal_month = fiscal_month_from_stmt(stmt_month, fy_end_month)\n",
    "    feats['fiscal_month_sin'] = np.sin(2 * np.pi * fiscal_month / 12.0)\n",
    "    feats['fiscal_month_cos'] = np.cos(2 * np.pi * fiscal_month / 12.0)\n",
    "    fiscal_quarter = fiscal_quarter_from_stmt(stmt_month, fy_end_month)\n",
    "\n",
    "    for q in range(1, 5):\n",
    "        feats[f'fiscal_q{q}'] = (fiscal_quarter == q).astype(float)\n",
    "    \n",
    "    feats = feats.replace([np.inf, -np.inf], np.nan)\n",
    "    feats = feats.sort_index().ffill().bfill()\n",
    "\n",
    "\n",
    "    return feats\n",
    "\n",
    "\n",
    "period_days = 365.0 if TARGET_FREQ == 'yearly' else 90.0\n",
    "growth_periods = 1 if TARGET_FREQ == 'yearly' else 4\n",
    "\n",
    "primary_ticker = normalize_ticker(PRIMARY_TICKER)\n",
    "features = compute_features(\n",
    "    bs,\n",
    "    is_df,\n",
    "    ticker = primary_ticker,\n",
    "    days = period_days,\n",
    "    growth_periods = growth_periods\n",
    ")\n",
    "features.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fda5da4",
   "metadata": {},
   "source": [
    "### 2.2 Dataset Assembly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86163dd5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-21T19:16:54.398744Z",
     "iopub.status.busy": "2026-01-21T19:16:54.398514Z",
     "iopub.status.idle": "2026-01-21T19:16:54.628671Z",
     "shell.execute_reply": "2026-01-21T19:16:54.627947Z"
    }
   },
   "outputs": [],
   "source": [
    "# Assemble aligned dataset across tickers with required columns.\n",
    "TARGET_BS = MODEL_CONFIG['target_bs']\n",
    "TARGET_LE = MODEL_CONFIG['target_le']\n",
    "NET_INCOME_COL = MODEL_CONFIG['net_income_col']\n",
    "STATE_COLS = MODEL_CONFIG['state_cols']\n",
    "\n",
    "\n",
    "def _has_any(df: pd.DataFrame, options: list[str]) -> bool:\n",
    "    \"\"\"Return True if any candidate column exists.\"\"\"\n",
    "\n",
    "    return any(c in df.columns for c in options)\n",
    "\n",
    "\n",
    "def missing_required_columns(bs: pd.DataFrame, is_df: pd.DataFrame) -> list[str]:\n",
    "    \"\"\"Return missing required columns for BS and IS.\"\"\"\n",
    "\n",
    "    missing = []\n",
    "\n",
    "    if not _has_any(bs, ['Total Assets', 'TotalAssets']):\n",
    "        missing.append('Total Assets')\n",
    "    \n",
    "    if not _has_any(bs, ['Total Liabilities', 'Total Liabilities', 'TotalLiabilities', 'Total Liabilities Net Minority Interest', 'TotalLiabilitiesNetMinorityInterest']):\n",
    "        missing.append('Total Liabilities')\n",
    "    \n",
    "    if not _has_any(bs, ['Total Equity', 'Stockholders Equity', 'StockholdersEquity', 'Total Equity Gross Minority Interest', 'TotalEquityGrossMinorityInterest']):\n",
    "        missing.append('Total Equity')\n",
    "    \n",
    "    if not _has_any(bs, ['Accounts Receivable', 'AccountsReceivable']):\n",
    "        missing.append('Accounts Receivable')\n",
    "    \n",
    "    if not _has_any(bs, ['Accounts Payable', 'AccountsPayable']):\n",
    "        missing.append('Accounts Payable')\n",
    "    \n",
    "    if not _has_any(bs, ['Inventory', 'Inventories']):\n",
    "        missing.append('Inventory')\n",
    "    \n",
    "    if not _has_any(bs, ['Net PPE', 'NetPPE']):\n",
    "        missing.append('Net PPE')\n",
    "    \n",
    "    if not _has_any(bs, ['Retained Earnings', 'RetainedEarnings']):\n",
    "        missing.append('Retained Earnings')\n",
    "\n",
    "    if not _has_any(is_df, ['Total Revenue', 'Operating Revenue', 'TotalRevenue', 'OperatingRevenue', 'Revenues']):\n",
    "        missing.append('Total Revenue')\n",
    "   \n",
    "    if not _has_any(is_df, ['Cost Of Revenue', 'Cost of Revenue', 'CostOfRevenue', 'ReconciledCostOfRevenue']):\n",
    "        missing.append('Cost Of Revenue')\n",
    "    \n",
    "    if not _has_any(is_df, ['Operating Income', 'OperatingIncome']):\n",
    "        missing.append('Operating Income')\n",
    "    \n",
    "    if not _has_any(is_df, ['Net Income', 'NetIncome', 'NetIncomeFromContinuingOperationNetMinorityInterest']):\n",
    "        missing.append('Net Income')\n",
    "\n",
    "\n",
    "    return missing\n",
    "\n",
    "\n",
    "def build_aligned_for_ticker(ticker: str) -> pd.DataFrame:\n",
    "    \"\"\"Build an aligned dataset for one ticker.\"\"\"\n",
    "\n",
    "    bs, is_df, freq = load_statements(ticker, freq = TARGET_FREQ)\n",
    "    missing = missing_required_columns(bs, is_df)\n",
    "    \n",
    "    if missing:\n",
    "\n",
    "        print(f\"{ticker}: skip, missing {missing}\")\n",
    "\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    period_days = 365.0 if freq == 'yearly' else 90.0\n",
    "    growth_periods = 1 if freq == 'yearly' else 4\n",
    "\n",
    "    features = compute_features(bs, is_df, ticker = ticker, days = period_days, growth_periods = growth_periods)\n",
    "    \n",
    "    # Use lagged features (t-1) to predict current targets (t).\n",
    "    features = features.shift(1)\n",
    "    targets = bs[TARGET_BS].copy()\n",
    "    net_income = _pick(is_df, ['Net Income', 'NetIncome', 'NetIncomeFromContinuingOperationNetMinorityInterest']).rename(NET_INCOME_COL)\n",
    "    net_income = net_income.reindex(targets.index)\n",
    "\n",
    "    # Align features, targets, and net income on shared dates.\n",
    "    dataset = features.join(targets, how = 'inner').join(net_income, how = 'inner')\n",
    "    dataset = dataset.dropna()\n",
    "\n",
    "    rev_series = _pick(is_df, ['Total Revenue', 'Operating Revenue', 'TotalRevenue', 'OperatingRevenue', 'Revenues'])\n",
    "    \n",
    "    # Shift state variables to create t-1 inputs.\n",
    "    prev_state_df = bs.reindex(columns = STATE_COLS).shift(1)\n",
    "    prev_state_df.columns = [f'prev_{c}' for c in STATE_COLS]\n",
    "    prev_state_df['prev_Total Revenue'] = rev_series.reindex(targets.index).shift(1)\n",
    "\n",
    "    # Combine current data with lagged state for modeling.\n",
    "    aligned = dataset.join(prev_state_df, how = 'inner').dropna()\n",
    "    aligned['ticker'] = ticker\n",
    "    aligned['stmt_freq'] = freq\n",
    "\n",
    "\n",
    "    return aligned\n",
    "\n",
    "\n",
    "# Aggregate aligned datasets across tickers.\n",
    "aligned_list = []\n",
    "\n",
    "for ticker in [normalize_ticker(t) for t in TICKERS]:\n",
    "\n",
    "    try:\n",
    "        aligned_t = build_aligned_for_ticker(ticker)\n",
    "\n",
    "        if aligned_t.empty:\n",
    "\n",
    "            print(f\"{ticker}: empty after alignment\")\n",
    "\n",
    "        else:\n",
    "\n",
    "            print(f\"{ticker}: aligned rows = {aligned_t.shape[0]}\")\n",
    "            aligned_list.append(aligned_t)\n",
    "\n",
    "    except Exception as exc:\n",
    "\n",
    "        print(f\"{ticker}: failed ({exc})\")\n",
    "\n",
    "if not aligned_list:\n",
    "\n",
    "    raise RuntimeError('No aligned data available')\n",
    "\n",
    "aligned = pd.concat(aligned_list, axis = 0).sort_index()\n",
    "prev_cols = [f'prev_{c}' for c in STATE_COLS] + ['prev_Total Revenue']\n",
    "drop_cols = TARGET_BS + [NET_INCOME_COL] + prev_cols + ['ticker', 'stmt_freq']\n",
    "FEATURE_COLS = [c for c in aligned.columns if c not in drop_cols]\n",
    "\n",
    "\n",
    "print('Dataset shape:', aligned.shape)\n",
    "print('Feature cols:', len(FEATURE_COLS), 'Target cols:', len(TARGET_LE) + 1)\n",
    "print('Tickers:', aligned['ticker'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e377b2b",
   "metadata": {},
   "source": [
    "### 2.3 Prev-state Matrix for Algebraic Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ea1502",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-21T19:16:54.630531Z",
     "iopub.status.busy": "2026-01-21T19:16:54.630290Z",
     "iopub.status.idle": "2026-01-21T19:16:54.636048Z",
     "shell.execute_reply": "2026-01-21T19:16:54.635192Z"
    }
   },
   "outputs": [],
   "source": [
    "# Build model-ready arrays for features, targets, and state inputs.\n",
    "X_feat = aligned[FEATURE_COLS].values.astype('float32')\n",
    "Y_bs = aligned[TARGET_LE].values.astype('float32')\n",
    "Y_earn = aligned[[NET_INCOME_COL]].values.astype('float32')\n",
    "X_prev = aligned[prev_cols].values.astype('float32')\n",
    "\n",
    "\n",
    "print('Aligned shapes:', X_feat.shape, X_prev.shape, Y_bs.shape, Y_earn.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86fa6ccd",
   "metadata": {},
   "source": [
    "### 2.4 Scaling (z-score) for Stability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b08c37",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-21T19:16:54.638143Z",
     "iopub.status.busy": "2026-01-21T19:16:54.637753Z",
     "iopub.status.idle": "2026-01-21T19:16:54.643830Z",
     "shell.execute_reply": "2026-01-21T19:16:54.642841Z"
    }
   },
   "outputs": [],
   "source": [
    "# Standardize inputs and targets for stable optimization.\n",
    "feat_scaler = StandardScaler()\n",
    "bs_scaler = StandardScaler()\n",
    "earn_scaler = StandardScaler()\n",
    "prev_scaler = StandardScaler()\n",
    "\n",
    "X_feat_scaled = feat_scaler.fit_transform(X_feat)\n",
    "Y_bs_scaled = bs_scaler.fit_transform(Y_bs)\n",
    "Y_earn_scaled = earn_scaler.fit_transform(Y_earn)\n",
    "X_prev_scaled = prev_scaler.fit_transform(X_prev)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5fede8",
   "metadata": {},
   "source": [
    "### 2.5 Train/Val Split on Scaled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7cd1fcd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-21T19:16:54.645955Z",
     "iopub.status.busy": "2026-01-21T19:16:54.645714Z",
     "iopub.status.idle": "2026-01-21T19:16:54.652634Z",
     "shell.execute_reply": "2026-01-21T19:16:54.651862Z"
    }
   },
   "outputs": [],
   "source": [
    "# Time-ordered split to reduce look-ahead leakage (per-ticker fixed windows).\n",
    "min_oos = 2\n",
    "min_val = 1\n",
    "\n",
    "n = X_feat_scaled.shape[0]\n",
    "train_mask = np.zeros(n, dtype = bool)\n",
    "val_mask = np.zeros(n, dtype = bool)\n",
    "test_mask = np.zeros(n, dtype = bool)\n",
    "\n",
    "for ticker in aligned['ticker'].unique():\n",
    "\n",
    "    pos = np.where(aligned['ticker'].values == ticker)[0]\n",
    "    pos = pos[np.argsort(aligned.index.values[pos])]\n",
    "\n",
    "    if len(pos) <= (min_val + 1):\n",
    "        train_mask[pos] = True\n",
    "\n",
    "        continue\n",
    "\n",
    "    oos_size = min(min_oos, max(1, len(pos) - min_val - 1))\n",
    "    test_start = len(pos) - oos_size\n",
    "    val_start = max(test_start - min_val, 0)\n",
    "\n",
    "    train_mask[pos[:val_start]] = True\n",
    "    val_mask[pos[val_start:test_start]] = True\n",
    "    test_mask[pos[test_start:]] = True\n",
    "\n",
    "X_train_feat = X_feat_scaled[train_mask]\n",
    "Y_train_bs = Y_bs_scaled[train_mask]\n",
    "Y_train_earn = Y_earn_scaled[train_mask]\n",
    "X_train_prev = X_prev_scaled[train_mask]\n",
    "\n",
    "X_val_feat = X_feat_scaled[val_mask]\n",
    "Y_val_bs = Y_bs_scaled[val_mask]\n",
    "Y_val_earn = Y_earn_scaled[val_mask]\n",
    "X_val_prev = X_prev_scaled[val_mask]\n",
    "\n",
    "X_test_feat = X_feat_scaled[test_mask]\n",
    "Y_test_bs = Y_bs_scaled[test_mask]\n",
    "Y_test_earn = Y_earn_scaled[test_mask]\n",
    "X_test_prev = X_prev_scaled[test_mask]\n",
    "\n",
    "test_index = aligned.index[test_mask]\n",
    "\n",
    "print('Scaled train:', X_train_feat.shape, Y_train_bs.shape, Y_train_earn.shape)\n",
    "print('Scaled val:', X_val_feat.shape, Y_val_bs.shape, Y_val_earn.shape)\n",
    "print('Scaled test:', X_test_feat.shape, Y_test_bs.shape, Y_test_earn.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa94b11e",
   "metadata": {},
   "source": [
    "## 3. TensorFlow\n",
    "---\n",
    "*Pareja/Pelaez Constrained*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7651e04f",
   "metadata": {},
   "source": [
    "### 3.1 TF Model with Algebraic Generator + Earnings Head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa64e104",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-21T19:16:54.654638Z",
     "iopub.status.busy": "2026-01-21T19:16:54.654320Z",
     "iopub.status.idle": "2026-01-21T19:16:54.842266Z",
     "shell.execute_reply": "2026-01-21T19:16:54.841414Z"
    }
   },
   "outputs": [],
   "source": [
    "class AlgebraicBS(keras.layers.Layer):\n",
    "    \"\"\"Layer that enforces algebraic balance sheet constraints.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize sublayers for balance sheet generation.\"\"\"\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.hidden = keras.layers.Dense(64, activation = 'relu')\n",
    "        self.rev_head = keras.layers.Dense(1, activation = 'relu')\n",
    "        self.cogs_head = keras.layers.Dense(1, activation = 'relu')\n",
    "        self.drivers = keras.layers.Dense(5)\n",
    "        self.margin_head = keras.layers.Dense(1)\n",
    "        self.payout_head = keras.layers.Dense(1)\n",
    "        self.earn_params = keras.layers.Dense(2, name = 'net_income_params')\n",
    "\n",
    "\n",
    "    def call(self, inputs: Tuple[tf.Tensor, tf.Tensor]):\n",
    "        \"\"\"Compute constrained balance sheet and earnings outputs.\"\"\"\n",
    "\n",
    "        if not isinstance(inputs, (tuple, list)):\n",
    "\n",
    "            raise TypeError(\"inputs must be (features, prev_state)\")\n",
    "\n",
    "        features, prev_state = inputs\n",
    "        ar_prev, ap_prev, inv_prev, ppe_prev, liab_prev, equity_prev, re_prev, rev_prev = tf.split(prev_state, num_or_size_splits = 8, axis = -1)\n",
    "        hidden = self.hidden(features)\n",
    "        rev_predicate = self.rev_head(hidden)\n",
    "        cogs_predicate = self.cogs_head(hidden)\n",
    "        drivers_raw = self.drivers(hidden)\n",
    "\n",
    "        dso = tf.nn.softplus(drivers_raw[:, 0:1])\n",
    "        dpo = tf.nn.softplus(drivers_raw[:, 1:2])\n",
    "        dih = tf.nn.softplus(drivers_raw[:, 2:3])\n",
    "        dep_rate = tf.nn.sigmoid(drivers_raw[:, 3:4]) * 0.2\n",
    "        capex_rate = tf.nn.sigmoid(drivers_raw[:, 4:5]) * 0.2\n",
    "        net_margin = tf.tanh(self.margin_head(hidden)) * 0.5\n",
    "        div_payout = tf.nn.sigmoid(self.payout_head(hidden))\n",
    "\n",
    "        sales_per_day = rev_predicate / 365.0\n",
    "        cogs_per_day = cogs_predicate / 365.0\n",
    "\n",
    "        ar_next = dso * sales_per_day\n",
    "        ap_next = dpo * cogs_per_day\n",
    "        inv_next = dih * cogs_per_day\n",
    "        dep = dep_rate * ppe_prev\n",
    "        capex = capex_rate * rev_predicate\n",
    "        ppe_next = ppe_prev + capex - dep\n",
    "        net_income = net_margin * rev_predicate\n",
    "        # TFP: output loc/scale parameters for earnings distribution.\n",
    "        earn_params = self.earn_params(hidden)\n",
    "        earn_predicate = earn_params\n",
    "        div = div_payout * net_income\n",
    "        re_next = re_prev + net_income - div\n",
    "\n",
    "        other_equity = tf.nn.relu(equity_prev - re_prev)\n",
    "\n",
    "        equity_next = re_next + other_equity\n",
    "\n",
    "        other_liab_prev = tf.nn.relu(liab_prev - ap_prev)\n",
    "        growth = tf.where(rev_prev > 0, rev_predicate / rev_prev - 1.0, tf.zeros_like(rev_predicate))\n",
    "\n",
    "        other_liab_next = other_liab_prev * (1.0 + growth)\n",
    "        liab_next = ap_next + other_liab_next\n",
    "        assets_wo_cash = ar_next + inv_next + ppe_next\n",
    "        cash_next = equity_next + liab_next - assets_wo_cash\n",
    "        assets_next = liab_next + equity_next\n",
    "        # Output liabilities and equity; assets are derived as L + E downstream.\n",
    "        bs_out = tf.concat([liab_next, equity_next], axis = -1)\n",
    "\n",
    "\n",
    "        return bs_out, earn_predicate\n",
    "\n",
    "\n",
    "def build_pareja_model(feat_dim: int, state_dim: int = 8):\n",
    "    \"\"\"Build a Pareja/Pelaez-constrained model.\"\"\"\n",
    "\n",
    "    feat_in = keras.Input(shape = (feat_dim,), name = 'features')\n",
    "    state_in = keras.Input(shape = (state_dim,), name = 'prev_state')\n",
    "    bs_out, earn_out = AlgebraicBS()([feat_in, state_in])\n",
    "    bs_out = keras.layers.Lambda(lambda x: x, name = 'bs_out')(bs_out)\n",
    "    earn_out = keras.layers.Lambda(lambda x: x, name = 'earn_params')(earn_out)\n",
    "    \n",
    "    \n",
    "    return keras.Model([feat_in, state_in], [bs_out, earn_out], name = 'bs_pareja_style')\n",
    "\n",
    "\n",
    "pareja_model = build_pareja_model(feat_dim = X_feat_scaled.shape[1], state_dim = X_prev_scaled.shape[1])\n",
    "pareja_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b09328",
   "metadata": {},
   "source": [
    "### 3.2 Tests / Sanity Checks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ec67bd",
   "metadata": {},
   "source": [
    "#### 3.2.1 Unit test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c9b991",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-21T19:16:54.844420Z",
     "iopub.status.busy": "2026-01-21T19:16:54.844081Z",
     "iopub.status.idle": "2026-01-21T19:16:54.859656Z",
     "shell.execute_reply": "2026-01-21T19:16:54.858799Z"
    }
   },
   "outputs": [],
   "source": [
    "# Fast unit checks on core helpers and feature output.\n",
    "print('Running Unit test...')\n",
    "\n",
    "try: \n",
    "    idx = pd.to_datetime(['2023-12-31', '2024-12-31'])\n",
    "\n",
    "    sample_bs = pd.DataFrame(\n",
    "        {\n",
    "            'TotalAssets': [100.0, 120.0],\n",
    "            'TotalLiabilities': [60.0, 70.0],\n",
    "            'StockholdersEquity': [40.0, 50.0],\n",
    "            'AccountsReceivable': [10.0, 12.0],\n",
    "            'AccountsPayable': [8.0, 9.0],\n",
    "            'Inventory': [5.0, 6.0],\n",
    "            'NetPPE': [20.0, 22.0],\n",
    "            'RetainedEarnings': [15.0, 18.0],\n",
    "        },\n",
    "\n",
    "        index = idx,\n",
    "    )\n",
    "\n",
    "    sample_is = pd.DataFrame(\n",
    "        {\n",
    "            'TotalRevenue': [80.0, 90.0],\n",
    "            'CostOfRevenue': [30.0, 35.0],\n",
    "            'OperatingIncome': [10.0, 12.0],\n",
    "            'NetIncome': [8.0, 9.0],\n",
    "        },\n",
    "\n",
    "        index = idx,\n",
    "    )\n",
    "\n",
    "    canon = canonicalize_bs(sample_bs)\n",
    "\n",
    "    assert 'Total Assets' in canon.columns, 'canonicalize_bs failed for Total Assets'\n",
    "    assert 'Total Liabilities' in canon.columns, 'canonicalize_bs failed for Total Liabilities'\n",
    "    assert 'Total Equity' in canon.columns, 'canonicalize_bs failed for Total Equity'\n",
    "\n",
    "    resid = identity_residual(canon)\n",
    "    assert np.allclose(resid.values, 0.0), 'identity_residual should be zero for balanced data'\n",
    "\n",
    "    missing = missing_required_columns(sample_bs, sample_is)\n",
    "    assert missing == [], f'missing_required_columns unexpected: {missing}'\n",
    "\n",
    "    features_test = compute_features(sample_bs, sample_is, days = 365.0, growth_periods = 1)\n",
    "\n",
    "    expected_cols = {\n",
    "        'dso', 'dpo', 'dih', 'gross_margin', 'op_margin', 'net_margin',\n",
    "        'rev_yoy', 'cogs_yoy', 'netinc_yoy', 'log_rev', 'log_assets'\n",
    "    }\n",
    "\n",
    "    assert expected_cols.issubset(set(features_test.columns)), 'compute_features missing expected columns'\n",
    "    assert np.isfinite(features_test.to_numpy()).all(), 'compute_features produced non-finite values'\n",
    "\n",
    "    print('Unit tests passed.')\n",
    "\n",
    "except Exception as e:\n",
    "    print('Unit tests failed:', e)\n",
    "\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fcb1fa",
   "metadata": {},
   "source": [
    "#### 3.2.2 Integration test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebbb7bcf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-21T19:16:54.861561Z",
     "iopub.status.busy": "2026-01-21T19:16:54.861226Z",
     "iopub.status.idle": "2026-01-21T19:16:54.913878Z",
     "shell.execute_reply": "2026-01-21T19:16:54.913097Z"
    }
   },
   "outputs": [],
   "source": [
    "# Minimal end-to-end sanity check of model outputs.\n",
    "print('Running Integration test...')\n",
    "\n",
    "try:\n",
    "    assert aligned.shape[0] > 0, 'aligned dataset is empty'\n",
    "    assert X_feat.shape[0] == Y_bs.shape[0] == Y_earn.shape[0] == X_prev.shape[0], 'array length mismatch'\n",
    "\n",
    "    test_batch = min(2, X_train_feat.shape[0])\n",
    "    assert test_batch > 0, 'empty training batch'\n",
    "\n",
    "    bs_hat, earn_hat = pareja_model([X_train_feat[:test_batch], X_train_prev[:test_batch]], training = False)\n",
    "    assert bs_hat.shape[-1] == len(TARGET_LE), 'unexpected BS output width'\n",
    "    assert earn_hat.shape[-1] == 2, 'unexpected earnings param width'\n",
    "\n",
    "    print('Integration tests passed.')\n",
    "\n",
    "except Exception as e:\n",
    "    print('Integration tests failed:', e)\n",
    "\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7dab72",
   "metadata": {},
   "source": [
    "### 3.2 Train/Evaluate\n",
    "*MAE on BS + TFP on Earnings*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973ce0f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-21T19:16:54.916032Z",
     "iopub.status.busy": "2026-01-21T19:16:54.915722Z",
     "iopub.status.idle": "2026-01-21T19:16:58.435056Z",
     "shell.execute_reply": "2026-01-21T19:16:58.434198Z"
    }
   },
   "outputs": [],
   "source": [
    "# Train with MAE on balance sheet and NLL on earnings.\n",
    "def negloglik(y_true, y_pred):\n",
    "    \"\"\"TFP: Normal NLL for earnings using loc/scale parameters.\"\"\"\n",
    "    \n",
    "    loc = y_pred[..., :1]\n",
    "    scale = tf.nn.softplus(y_pred[..., 1:]) + 1e-3\n",
    "    dist = tfp.distributions.Normal(loc = loc, scale = scale)\n",
    "    \n",
    "\n",
    "    return -dist.log_prob(y_true)\n",
    "\n",
    "\n",
    "pareja_model.compile(\n",
    "    optimizer = keras.optimizers.Adam(1e-3),\n",
    "    loss = [keras.losses.MeanAbsoluteError(), negloglik],\n",
    "    loss_weights = [1.0, 0.3],\n",
    ")\n",
    "\n",
    "hist = pareja_model.fit(\n",
    "    [X_train_feat, X_train_prev], [Y_train_bs, Y_train_earn],\n",
    "    \n",
    "    validation_data = (\n",
    "        [X_val_feat, X_val_prev], [Y_val_bs, Y_val_earn]\n",
    "    ) if len(X_val_feat) > 0 else None,\n",
    "    \n",
    "    epochs = 20,\n",
    "    batch_size = 2,\n",
    "    verbose = 0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb78230f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-21T19:16:58.437154Z",
     "iopub.status.busy": "2026-01-21T19:16:58.436779Z",
     "iopub.status.idle": "2026-01-21T19:16:58.452095Z",
     "shell.execute_reply": "2026-01-21T19:16:58.451222Z"
    }
   },
   "outputs": [],
   "source": [
    "# Invert scaling for outputs in original units.\n",
    "bs_predicate_scaled, earn_params_scaled = pareja_model([X_feat_scaled, X_prev_scaled], training = False)\n",
    "bs_predicate = bs_scaler.inverse_transform(bs_predicate_scaled.numpy())\n",
    "earn_loc_scaled = earn_params_scaled[:, :1]\n",
    "earn_scale_scaled = tf.nn.softplus(earn_params_scaled[:, 1:]) + 1e-3\n",
    "earn_predicate = earn_scaler.inverse_transform(earn_loc_scaled.numpy())\n",
    "earn_predicate_std = earn_scale_scaled.numpy() * earn_scaler.scale_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db6ed20",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-21T19:16:58.454114Z",
     "iopub.status.busy": "2026-01-21T19:16:58.453832Z",
     "iopub.status.idle": "2026-01-21T19:16:58.485754Z",
     "shell.execute_reply": "2026-01-21T19:16:58.484640Z"
    }
   },
   "outputs": [],
   "source": [
    "# Reconstruct full balance sheet and error metrics.\n",
    "bs_predicate_df = pd.DataFrame(bs_predicate, columns = TARGET_LE, index = aligned.index)\n",
    "assets_predicate = bs_predicate_df['Total Liabilities'] + bs_predicate_df['Total Equity']\n",
    "bs_predicate_full = bs_predicate_df.copy()\n",
    "bs_predicate_full['Total Assets'] = assets_predicate\n",
    "bs_predicate_full = bs_predicate_full[TARGET_BS]\n",
    "resid_predicate = bs_predicate_full['Total Assets'] - (bs_predicate_full['Total Liabilities'] + bs_predicate_full['Total Equity'])\n",
    "\n",
    "pred_full = bs_predicate_full.copy()\n",
    "pred_full['ticker'] = aligned['ticker'].values\n",
    "pred_full['stmt_freq'] = aligned['stmt_freq'].values\n",
    "pred_full['pred_net_income'] = earn_predicate.flatten()\n",
    "pred_full['pred_net_income_std'] = earn_predicate_std.flatten()\n",
    "pred_full['pred_resid'] = pred_full['Total Assets'] - (pred_full['Total Liabilities'] + pred_full['Total Equity'])\n",
    "\n",
    "actual_bs = aligned[TARGET_BS].copy()\n",
    "actual_bs.columns = [f'actual_{c}' for c in actual_bs.columns]\n",
    "pred_full = pd.concat([pred_full, actual_bs], axis = 1)\n",
    "pred_full['actual_net_income'] = aligned[NET_INCOME_COL].values\n",
    "\n",
    "pred_full['err_assets'] = pred_full['Total Assets'] - pred_full['actual_Total Assets']\n",
    "pred_full['err_liab'] = pred_full['Total Liabilities'] - pred_full['actual_Total Liabilities']\n",
    "pred_full['err_equity'] = pred_full['Total Equity'] - pred_full['actual_Total Equity']\n",
    "pred_full['err_net_income'] = pred_full['pred_net_income'] - pred_full['actual_net_income']\n",
    "pred_full['abs_err_assets'] = pred_full['err_assets'].abs()\n",
    "pred_full['abs_err_liab'] = pred_full['err_liab'].abs()\n",
    "pred_full['abs_err_equity'] = pred_full['err_equity'].abs()\n",
    "pred_full['abs_err_net_income'] = pred_full['err_net_income'].abs()\n",
    "\n",
    "# Aggregate per-ticker diagnostics for reporting.\n",
    "summary = pred_full.groupby('ticker').agg(\n",
    "    samples = ('pred_net_income', 'size'),\n",
    "    mean_pred_assets = ('Total Assets', 'mean'),\n",
    "    mean_pred_liab = ('Total Liabilities', 'mean'),\n",
    "    mean_pred_equity = ('Total Equity', 'mean'),\n",
    "    mean_pred_net_income = ('pred_net_income', 'mean'),\n",
    "    mean_pred_net_income_std = ('pred_net_income_std', 'mean'),\n",
    "    mean_actual_assets = ('actual_Total Assets', 'mean'),\n",
    "    mean_actual_liab = ('actual_Total Liabilities', 'mean'),\n",
    "    mean_actual_equity = ('actual_Total Equity', 'mean'),\n",
    "    mean_actual_net_income = ('actual_net_income', 'mean'),\n",
    "    mae_assets = ('abs_err_assets', 'mean'),\n",
    "    mae_liab = ('abs_err_liab', 'mean'),\n",
    "    mae_equity = ('abs_err_equity', 'mean'),\n",
    "    mae_net_income = ('abs_err_net_income', 'mean'),\n",
    ")\n",
    "\n",
    "def format_df_for_view(df: pd.DataFrame, decimals: int = 2) -> pd.DataFrame:\n",
    "    \"\"\"Create a display-only view with formatted numerics.\"\"\"\n",
    "\n",
    "    view = df.copy()\n",
    "    num_cols = view.select_dtypes(include = [np.number]).columns\n",
    "    fmt = f\"{{:,.{decimals}f}}\"\n",
    "    view[num_cols] = view[num_cols].map(lambda v: \"\" if pd.isna(v) else fmt.format(v))\n",
    "\n",
    "\n",
    "    return view\n",
    "\n",
    "\n",
    "pred_full = pred_full.reset_index().rename(columns = {'index': 'stmt_date'})\n",
    "pred_full['stmt_year'] = pred_full['stmt_date'].dt.year\n",
    "stmt_month = pred_full['stmt_date'].dt.month\n",
    "fy_end_month = pred_full['ticker'].map(FISCAL_YEAR_END_MONTHS)\n",
    "fiscal_quarter = fiscal_quarter_from_stmt(stmt_month, fy_end_month)\n",
    "\n",
    "for q in range(1, 5):\n",
    "    pred_full[f'fiscal_q{q}'] = (fiscal_quarter == q).astype(int)\n",
    "\n",
    "pred_full_view = pred_full.set_index(['ticker', 'fiscal_q1', 'fiscal_q2', 'fiscal_q3', 'fiscal_q4'])\n",
    "pred_full_view = format_df_for_view(pred_full_view)\n",
    "summary_view = format_df_for_view(summary)\n",
    "\n",
    "earn_head_str = np.array2string(\n",
    "    earn_predicate.flatten(),\n",
    "    formatter = {\"float_kind\": lambda v: f\"{v:,.2f}\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17135fa1",
   "metadata": {},
   "source": [
    "## 4. Results\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994632b7",
   "metadata": {},
   "source": [
    "### 4.1 Final Train Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39fb4ced",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-21T19:16:58.488065Z",
     "iopub.status.busy": "2026-01-21T19:16:58.487838Z",
     "iopub.status.idle": "2026-01-21T19:16:58.494503Z",
     "shell.execute_reply": "2026-01-21T19:16:58.493690Z"
    }
   },
   "outputs": [],
   "source": [
    "loss_rows = [\n",
    "    {'metric': k, 'value': v[-1]}\n",
    "    for k, v in hist.history.items()\n",
    "\n",
    "    if 'loss' in k\n",
    "]\n",
    "loss_df = pd.DataFrame(loss_rows).sort_values('metric').reset_index(drop = True)\n",
    "\n",
    "\n",
    "loss_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241f8421",
   "metadata": {},
   "source": [
    "### 4.2 Earnings NLL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e21ae8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-21T19:16:58.496224Z",
     "iopub.status.busy": "2026-01-21T19:16:58.495949Z",
     "iopub.status.idle": "2026-01-21T19:16:58.698618Z",
     "shell.execute_reply": "2026-01-21T19:16:58.697648Z"
    }
   },
   "outputs": [],
   "source": [
    "# Visualize training curves for earnings NLL.\n",
    "nll_key = 'earn_params_loss'\n",
    "val_nll_key = 'val_earn_params_loss'\n",
    "\n",
    "if nll_key in hist.history:\n",
    "    print('NLL curve (train):', '\\n', hist.history[nll_key], '\\n')\n",
    "\n",
    "print(\"=\" * 100, '\\n')\n",
    "\n",
    "if val_nll_key in hist.history:\n",
    "    print('NLL curve (val):', '\\n', hist.history[val_nll_key], '\\n')\n",
    "\n",
    "if nll_key in hist.history:\n",
    "    \n",
    "    plt.figure(figsize = (12, 4), dpi = 250)\n",
    "    plt.plot(hist.history[nll_key], label = 'train_nll')\n",
    "\n",
    "    if val_nll_key in hist.history:\n",
    "        plt.plot(hist.history[val_nll_key], label = 'val_nll')\n",
    "    \n",
    "    plt.title('Earnings NLL Curve')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('NLL')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5116ffbd",
   "metadata": {},
   "source": [
    "### 4.3 Per-Ticker Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1453f5e3",
   "metadata": {},
   "source": [
    "#### 4.3.1 Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6124a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-21T19:16:58.700642Z",
     "iopub.status.busy": "2026-01-21T19:16:58.700414Z",
     "iopub.status.idle": "2026-01-21T19:16:58.711220Z",
     "shell.execute_reply": "2026-01-21T19:16:58.710322Z"
    }
   },
   "outputs": [],
   "source": [
    "summary_view"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15bb6c1c",
   "metadata": {},
   "source": [
    "#### 4.3.2 Prediction Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631e5471",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-21T19:16:58.713146Z",
     "iopub.status.busy": "2026-01-21T19:16:58.712856Z",
     "iopub.status.idle": "2026-01-21T19:17:00.174591Z",
     "shell.execute_reply": "2026-01-21T19:17:00.173724Z"
    }
   },
   "outputs": [],
   "source": [
    "# Visualize predicted vs actual net income over time per ticker.\n",
    "plot_df = pred_full.copy()\n",
    "\n",
    "if TARGET_FREQ == 'yearly':\n",
    "    plot_df['period'] = plot_df['stmt_year']\n",
    "    x_label = 'Year'\n",
    "    title_suffix = 'Year'\n",
    "\n",
    "else:\n",
    "    plot_df['period'] = plot_df['stmt_date'].dt.to_period('Q')\n",
    "    x_label = 'Quarter'\n",
    "    title_suffix = 'Quarter'\n",
    "\n",
    "period_df = plot_df.groupby(['ticker', 'period']).agg(\n",
    "    pred_net_income = ('pred_net_income', 'mean'),\n",
    "    actual_net_income = ('actual_net_income', 'mean'),\n",
    "    pred_assets = ('Total Assets', 'mean'),\n",
    "    actual_assets = ('actual_Total Assets', 'mean'),\n",
    ")\n",
    "\n",
    "period_df = period_df.reset_index()\n",
    "tickers = sorted(period_df['ticker'].unique())\n",
    "ncols = 3\n",
    "nrows = int(np.ceil(len(tickers) / ncols))\n",
    "\n",
    "fig, axes = plt.subplots(nrows, ncols, figsize = (5 * ncols, 3.5 * nrows), sharex = False, dpi = 250)\n",
    "axes = np.array(axes).reshape(-1)\n",
    "\n",
    "for ax, ticker in zip(axes, tickers):\n",
    "\n",
    "    data = period_df[period_df['ticker'] == ticker].sort_values('period')\n",
    "    x_vals = data['period'].astype(str) if TARGET_FREQ != 'yearly' else data['period']\n",
    "    ax.plot(x_vals, data['actual_net_income'], label = 'actual_net_income', color = 'white')\n",
    "    ax.plot(x_vals, data['pred_net_income'], label = 'pred_net_income', color = 'red')\n",
    "    ax.set_title(ticker)\n",
    "    ax.set_xlabel(x_label)\n",
    "    ax.set_ylabel('Net Income')\n",
    "    ax.tick_params(axis = 'x', labelsize = 8, rotation = 45)\n",
    "\n",
    "    if TARGET_FREQ != 'yearly':\n",
    "        ax.tick_params(axis = 'x', rotation = 45)\n",
    "\n",
    "    ax.legend(fontsize = 6)\n",
    "\n",
    "for ax in axes[len(tickers):]:\n",
    "    ax.axis('off')\n",
    "\n",
    "fig.suptitle(f'Predicted vs Actual Net Income by {title_suffix.upper()}', y = 1.02)\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea59ac8a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-21T19:17:00.180111Z",
     "iopub.status.busy": "2026-01-21T19:17:00.179801Z",
     "iopub.status.idle": "2026-01-21T19:17:01.629305Z",
     "shell.execute_reply": "2026-01-21T19:17:01.628419Z"
    }
   },
   "outputs": [],
   "source": [
    "# Visualize predicted vs actual total assets over time per ticker.\n",
    "fig, axes = plt.subplots(nrows, ncols, figsize = (5 * ncols, 3.5 * nrows), sharex = False, dpi = 250)\n",
    "axes = np.array(axes).reshape(-1)\n",
    "\n",
    "for ax, ticker in zip(axes, tickers):\n",
    "\n",
    "    data = period_df[period_df['ticker'] == ticker].sort_values('period')\n",
    "    x_vals = data['period'].astype(str) if TARGET_FREQ != 'yearly' else data['period']\n",
    "    ax.plot(x_vals, data['actual_assets'], label = 'actual_assets', color = 'white')\n",
    "    ax.plot(x_vals, data['pred_assets'], label = 'pred_assets', color = 'red')\n",
    "    ax.set_title(ticker)\n",
    "    ax.set_xlabel(x_label)\n",
    "    ax.set_ylabel('Total Assets')\n",
    "    ax.tick_params(axis = 'x', labelsize = 8, rotation = 45)\n",
    "\n",
    "    if TARGET_FREQ != 'yearly':\n",
    "        ax.tick_params(axis = 'x', rotation = 45)\n",
    "\n",
    "    ax.legend(fontsize = 6)\n",
    "\n",
    "for ax in axes[len(tickers):]:\n",
    "    ax.axis('off')\n",
    "\n",
    "fig.suptitle(f'Predicted vs Actual Assets by {title_suffix.upper()}', y = 1.02)\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86b8075",
   "metadata": {},
   "source": [
    "#### 4.3.3 Full Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b979a47",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-21T19:17:01.634036Z",
     "iopub.status.busy": "2026-01-21T19:17:01.633785Z",
     "iopub.status.idle": "2026-01-21T19:17:01.656391Z",
     "shell.execute_reply": "2026-01-21T19:17:01.655416Z"
    }
   },
   "outputs": [],
   "source": [
    "pred_full_view"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e511984",
   "metadata": {},
   "source": [
    "## 5. Out of Sample Test\n",
    "---\n",
    "Evaluate the trained model on a held-out tail of the time series."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54478592",
   "metadata": {},
   "source": [
    "### 5.1 OOS Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c2c8d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-21T19:17:01.658369Z",
     "iopub.status.busy": "2026-01-21T19:17:01.658081Z",
     "iopub.status.idle": "2026-01-21T19:17:01.701769Z",
     "shell.execute_reply": "2026-01-21T19:17:01.700955Z"
    }
   },
   "outputs": [],
   "source": [
    "# Out-of-sample evaluation on the held-out tail.\n",
    "\n",
    "if X_test_feat.shape[0] == 0:\n",
    "    print('OOS: no samples available for evaluation.')\n",
    "\n",
    "else:\n",
    "    bs_test_scaled, earn_test_params_scaled = pareja_model([X_test_feat, X_test_prev], training = False)\n",
    "    bs_test_pred = bs_scaler.inverse_transform(bs_test_scaled.numpy())\n",
    "    earn_loc_scaled = earn_test_params_scaled[:, :1]\n",
    "    earn_scale_scaled = tf.nn.softplus(earn_test_params_scaled[:, 1:]) + 1e-3\n",
    "    earn_test_pred = earn_scaler.inverse_transform(earn_loc_scaled.numpy())\n",
    "    earn_test_pred_std = earn_scale_scaled.numpy() * earn_scaler.scale_[0]\n",
    "\n",
    "    aligned_test = aligned.iloc[test_mask].copy()\n",
    "    pred_le = pd.DataFrame(bs_test_pred, columns = TARGET_LE, index = aligned_test.index)\n",
    "    pred_assets = pred_le['Total Liabilities'] + pred_le['Total Equity']\n",
    "\n",
    "    actual_liab = aligned_test['Total Liabilities']\n",
    "    actual_equity = aligned_test['Total Equity']\n",
    "    actual_assets = aligned_test['Total Assets']\n",
    "    actual_earn = aligned_test[NET_INCOME_COL]\n",
    "\n",
    "    metrics = pd.DataFrame(\n",
    "        {\n",
    "            'mae_liab': [(pred_le['Total Liabilities'] - actual_liab).abs().mean()],\n",
    "            'mae_equity': [(pred_le['Total Equity'] - actual_equity).abs().mean()],\n",
    "            'mae_assets': [(pred_assets - actual_assets).abs().mean()],\n",
    "            'mae_net_income': [np.abs(earn_test_pred.flatten() - actual_earn.values).mean()],\n",
    "            'identity_resid_mean': [(pred_assets - (pred_le['Total Liabilities'] + pred_le['Total Equity'])).abs().mean()],\n",
    "        }\n",
    "    )\n",
    "\n",
    "    per_ticker_metrics = aligned_test.copy()\n",
    "    per_ticker_metrics['pred_liab'] = pred_le['Total Liabilities']\n",
    "    per_ticker_metrics['pred_equity'] = pred_le['Total Equity']\n",
    "    per_ticker_metrics['pred_assets'] = pred_assets\n",
    "    per_ticker_metrics['pred_net_income'] = earn_test_pred.flatten()\n",
    "    per_ticker_metrics['err_liab'] = per_ticker_metrics['pred_liab'] - actual_liab\n",
    "    per_ticker_metrics['err_equity'] = per_ticker_metrics['pred_equity'] - actual_equity\n",
    "    per_ticker_metrics['err_assets'] = per_ticker_metrics['pred_assets'] - actual_assets\n",
    "    per_ticker_metrics['err_net_income'] = per_ticker_metrics['pred_net_income'] - actual_earn.values\n",
    "\n",
    "    per_ticker_metrics = per_ticker_metrics.groupby('ticker').agg(\n",
    "        samples = ('err_net_income', 'size'),\n",
    "        mae_liab = ('err_liab', lambda s: s.abs().mean()),\n",
    "        mae_equity = ('err_equity', lambda s: s.abs().mean()),\n",
    "        mae_assets = ('err_assets', lambda s: s.abs().mean()),\n",
    "        mae_net_income = ('err_net_income', lambda s: s.abs().mean()),\n",
    "    ).sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42b6142",
   "metadata": {},
   "source": [
    "### 5.2 OOS Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058a7c13",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-21T19:17:01.703791Z",
     "iopub.status.busy": "2026-01-21T19:17:01.703492Z",
     "iopub.status.idle": "2026-01-21T19:17:01.709602Z",
     "shell.execute_reply": "2026-01-21T19:17:01.708675Z"
    }
   },
   "outputs": [],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26974fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "per_ticker_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a05457",
   "metadata": {},
   "source": [
    "### 5.3 OOS Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac14fdca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-21T19:17:01.711514Z",
     "iopub.status.busy": "2026-01-21T19:17:01.711294Z",
     "iopub.status.idle": "2026-01-21T19:17:01.719447Z",
     "shell.execute_reply": "2026-01-21T19:17:01.718595Z"
    }
   },
   "outputs": [],
   "source": [
    "# Diagnostics for per-ticker split sizes.\n",
    "\n",
    "diag_rows = []\n",
    "\n",
    "for ticker in aligned['ticker'].unique():\n",
    "    pos = np.where(aligned['ticker'].values == ticker)[0]\n",
    "    pos = pos[np.argsort(aligned.index.values[pos])]\n",
    "    diag_rows.append(\n",
    "        {\n",
    "            'ticker': ticker,\n",
    "            'total_rows': len(pos),\n",
    "            'train_rows': int(train_mask[pos].sum()),\n",
    "            'val_rows': int(val_mask[pos].sum()),\n",
    "            'test_rows': int(test_mask[pos].sum()),\n",
    "        }\n",
    "    )\n",
    "\n",
    "diag_df = pd.DataFrame(diag_rows).sort_values('ticker')\n",
    "\n",
    "\n",
    "diag_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25598f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-21T19:17:01.721460Z",
     "iopub.status.busy": "2026-01-21T19:17:01.721029Z",
     "iopub.status.idle": "2026-01-21T19:17:04.591372Z",
     "shell.execute_reply": "2026-01-21T19:17:04.590523Z"
    }
   },
   "outputs": [],
   "source": [
    "# OOS plots for net income and total assets.\n",
    "\n",
    "if X_test_feat.shape[0] == 0:\n",
    "    print('OOS: no samples available for plotting.')\n",
    "\n",
    "else:\n",
    "    oos_df = aligned_test.copy()\n",
    "    oos_df['pred_net_income'] = earn_test_pred.flatten()\n",
    "    oos_df['pred_total_assets'] = pred_assets.values\n",
    "    oos_df['actual_net_income'] = actual_earn.values\n",
    "    oos_df['actual_total_assets'] = actual_assets.values\n",
    "\n",
    "    if TARGET_FREQ == 'yearly':\n",
    "\n",
    "        oos_df['period'] = oos_df.index.year\n",
    "        x_label = 'Year'\n",
    "        title_suffix = 'Year'\n",
    "\n",
    "    else:\n",
    "        oos_df['period'] = oos_df.index.to_period('Q')\n",
    "        x_label = 'Quarter'\n",
    "        title_suffix = 'Quarter'\n",
    "\n",
    "    period_oos = oos_df.groupby(['ticker', 'period']).agg(\n",
    "        pred_net_income = ('pred_net_income', 'mean'),\n",
    "        actual_net_income = ('actual_net_income', 'mean'),\n",
    "        pred_assets = ('pred_total_assets', 'mean'),\n",
    "        actual_assets = ('actual_total_assets', 'mean'),\n",
    "    ).reset_index()\n",
    "\n",
    "    tickers = sorted(period_oos['ticker'].unique())\n",
    "\n",
    "    if not tickers:\n",
    "        print('OOS: no tickers available for plotting.')\n",
    "\n",
    "    else:\n",
    "        ncols = 3\n",
    "        nrows = int(np.ceil(len(tickers) / ncols))\n",
    "\n",
    "        fig, axes = plt.subplots(nrows, ncols, figsize = (5 * ncols, 3.5 * nrows), sharex = False, dpi = 250)\n",
    "        axes = np.array(axes).reshape(-1)\n",
    "\n",
    "        for ax, ticker in zip(axes, tickers):\n",
    "\n",
    "            data = period_oos[period_oos['ticker'] == ticker].sort_values('period')\n",
    "            x_vals = data['period'].astype(str) if TARGET_FREQ != 'yearly' else data['period']\n",
    "            ax.plot(x_vals, data['actual_net_income'], label = 'actual_net_income', color = 'white', marker = 'o', markersize = 4, linewidth = 1.5)\n",
    "            ax.plot(x_vals, data['pred_net_income'], label = 'pred_net_income', color = 'red', marker = 'o', markersize = 4, linewidth = 1.5)\n",
    "            ax.set_title(ticker)\n",
    "            ax.set_xlabel(x_label)\n",
    "            ax.set_ylabel('Net Income')\n",
    "            ax.tick_params(axis = 'x', labelsize = 8, rotation = 45)\n",
    "            ax.legend(fontsize = 6)\n",
    "            ax.grid(True, alpha = 0.2)\n",
    "\n",
    "        for ax in axes[len(tickers):]:\n",
    "            ax.axis('off')\n",
    "\n",
    "        fig.suptitle(f'OOS Predicted vs Actual Net Income by {title_suffix.upper()}', y = 1.02)\n",
    "        fig.tight_layout()\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "        fig, axes = plt.subplots(nrows, ncols, figsize = (5 * ncols, 3.5 * nrows), sharex = False, dpi = 250)\n",
    "        axes = np.array(axes).reshape(-1)\n",
    "\n",
    "        for ax, ticker in zip(axes, tickers):\n",
    "\n",
    "            data = period_oos[period_oos['ticker'] == ticker].sort_values('period')\n",
    "            x_vals = data['period'].astype(str) if TARGET_FREQ != 'yearly' else data['period']\n",
    "            ax.plot(x_vals, data['actual_assets'], label = 'actual_assets', color = 'white', marker = 'o', markersize = 4, linewidth = 1.5)\n",
    "            ax.plot(x_vals, data['pred_assets'], label = 'pred_assets', color = 'red', marker = 'o', markersize = 4, linewidth = 1.5)\n",
    "            ax.set_title(ticker)\n",
    "            ax.set_xlabel(x_label)\n",
    "            ax.set_ylabel('Total Assets')\n",
    "            ax.tick_params(axis = 'x', labelsize = 8, rotation = 45)\n",
    "            ax.legend(fontsize = 6)\n",
    "            ax.grid(True, alpha = 0.2)\n",
    "\n",
    "        for ax in axes[len(tickers):]:\n",
    "            ax.axis('off')\n",
    "\n",
    "        fig.suptitle(f'OOS Predicted vs Actual Assets by {title_suffix.upper()}', y = 1.02)\n",
    "        fig.tight_layout()\n",
    "        \n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d3c271",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
