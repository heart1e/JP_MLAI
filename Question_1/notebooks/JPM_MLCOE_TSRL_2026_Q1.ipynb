{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1341ec9",
   "metadata": {},
   "source": [
    "# **JPM MLCOE TSRL 2026 Q1**\n",
    "---\n",
    "**Heartie CHEN**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6e7d97",
   "metadata": {},
   "source": [
    "## 0. Global Configurations\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92bae7c9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'yfinance'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01myfinance\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01myf\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m keras\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'yfinance'"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from typing import Tuple\n",
    "\n",
    "\n",
    "pd.set_option('display.float_format', lambda v: f\"{v:,.2f}\")\n",
    "\n",
    "\n",
    "print('yfinance:', yf.__version__)\n",
    "print('pandas:', pd.__version__)\n",
    "print('tensorflow:', tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9fb8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 3\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.keras.utils.set_random_seed(SEED)\n",
    "tf.config.experimental.enable_op_determinism()\n",
    "\n",
    "DATA_DIR = Path(\"..\").resolve() / \"data\" / \"yfinance\" # \"sec\" / \"yfinance\"\n",
    "DATA_DIR.mkdir(parents = True, exist_ok = True)\n",
    "TARGET_FREQ = 'yearly' # 'quarterly' / 'yearly'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5489494f",
   "metadata": {},
   "source": [
    "## 1. Data Pipeline\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f2a2ad",
   "metadata": {},
   "source": [
    "### 1.1 Column Aliases and Identity Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3145050",
   "metadata": {},
   "outputs": [],
   "source": [
    "BS_ALIASES = {\n",
    "    \"Total Assets\": [\"Total Assets\", \"TotalAssets\"],\n",
    "    \"Total Liabilities\": [\n",
    "        \"Total Liab\", \"Total Liabilities\", \"Total Liabilities Net Minority Interest\",\n",
    "        \"TotalLiabilitiesNetMinorityInterest\", \"TotalLiabilities\"\n",
    "    ],\n",
    "    \"Total Equity\": [\n",
    "        \"Total Stockholder Equity\", \"Total Equity Gross Minority Interest\",\n",
    "        \"Stockholders Equity\", \"TotalEquityGrossMinorityInterest\", \"StockholdersEquity\"\n",
    "    ],\n",
    "    \"Accounts Receivable\": [\"Accounts Receivable\", \"AccountsReceivable\"],\n",
    "    \"Accounts Payable\": [\"Accounts Payable\", \"AccountsPayable\"],\n",
    "    \"Net PPE\": [\"Net PPE\", \"NetPPE\"],\n",
    "    \"Retained Earnings\": [\"Retained Earnings\", \"RetainedEarnings\"],\n",
    "    \"Inventory\": [\"Inventory\", \"Inventories\"],\n",
    "}\n",
    "\n",
    "\n",
    "def canonicalize_bs(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Return a balance sheet with canonical column names.\"\"\"\n",
    "\n",
    "    rename_map = {}\n",
    "\n",
    "    for canon, candidates in BS_ALIASES.items():\n",
    "        for c in candidates:\n",
    "\n",
    "            if c in df.columns:\n",
    "                rename_map[c] = canon\n",
    "                \n",
    "                break\n",
    "\n",
    "\n",
    "    return df.rename(columns = rename_map)\n",
    "\n",
    "\n",
    "def identity_residual(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"Compute balance sheet identity residuals.\"\"\"\n",
    "\n",
    "    if \"Total Liabilities\" not in df.columns or \"Total Equity\" not in df.columns:\n",
    "        df = canonicalize_bs(df)\n",
    "    \n",
    "    required = [\"Total Assets\", \"Total Liabilities\", \"Total Equity\"]\n",
    "    missing = [c for c in required if c not in df]\n",
    "\n",
    "    if missing:\n",
    "\n",
    "        raise KeyError(f\"Missing columns: {missing}\")\n",
    "\n",
    "\n",
    "    return df[\"Total Assets\"] - (df[\"Total Liabilities\"] + df[\"Total Equity\"])\n",
    "\n",
    "\n",
    "def summarize_identity(resid: pd.Series) -> pd.Series:\n",
    "    \"\"\"Summarize residual statistics.\"\"\"\n",
    "\n",
    "    return pd.Series({\n",
    "\n",
    "        \"mean\": resid.mean(),\n",
    "        \"std\": resid.std(),\n",
    "        \"max_abs\": resid.abs().max(),\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2590c66",
   "metadata": {},
   "source": [
    "### 1.2 Load Data with Caching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe162e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "SPECIAL_TICKERS = {\n",
    "    \"700\": \"0700.HK\",\n",
    "    \"1810\": \"1810.HK\",\n",
    "    \"9633\": \"9633.HK\",\n",
    "    \"9987\": \"9987.HK\",\n",
    "    \"9988\": \"9988.HK\",\n",
    "    \"BRK B\": \"BRK-B\",\n",
    "    \"NESN\": \"NESN.SW\",\n",
    "}\n",
    "\n",
    "\n",
    "def normalize_ticker(raw: str) -> str:\n",
    "    \"\"\"Normalize tickers and apply project-specific mappings.\"\"\"\n",
    "\n",
    "    value = raw.strip()\n",
    "    upper = value.upper()\n",
    "\n",
    "    if upper in SPECIAL_TICKERS:\n",
    "\n",
    "        return SPECIAL_TICKERS[upper]\n",
    "\n",
    "    if re.fullmatch(r\"\\d+\", value):\n",
    "\n",
    "        return value.zfill(4) + \".HK\"\n",
    "\n",
    "\n",
    "    return upper\n",
    "\n",
    "\n",
    "def slugify(ticker: str) -> str:\n",
    "    \"\"\"Create a filesystem-friendly slug for a ticker.\"\"\"\n",
    "\n",
    "    return re.sub(r\"[^a-z0-9]+\", \"_\", ticker.lower()).strip(\"_\")\n",
    "\n",
    "\n",
    "def _fetch_statements(tkr, freq: str):\n",
    "    \"\"\"Fetch statements from Yahoo Finance for a ticker.\"\"\"\n",
    "\n",
    "    bs = tkr.get_balance_sheet(freq = freq)\n",
    "    is_df = tkr.get_financials(freq = freq)\n",
    "\n",
    "    if bs is None or is_df is None:\n",
    "\n",
    "        return pd.DataFrame(), pd.DataFrame()\n",
    "\n",
    "    bs = bs.T.sort_index()\n",
    "    is_df = is_df.T.sort_index()\n",
    "\n",
    "\n",
    "    return bs, is_df\n",
    "\n",
    "\n",
    "def _load_cached(path: Path) -> pd.DataFrame:\n",
    "    \"\"\"Load a cached statement CSV if available.\"\"\"\n",
    "\n",
    "    return pd.read_csv(path, index_col = 0, parse_dates = True)\n",
    "\n",
    "\n",
    "def load_statements(ticker: str, freq: str = TARGET_FREQ):\n",
    "    \"\"\"Load or fetch statements for a ticker and frequency.\"\"\"\n",
    "\n",
    "    ticker = normalize_ticker(ticker)\n",
    "    slug = slugify(ticker)\n",
    "    freq = freq.lower()\n",
    "\n",
    "    data_dir = DATA_DIR / freq\n",
    "    data_dir.mkdir(parents = True, exist_ok = True)\n",
    "\n",
    "    bs_path = data_dir / f\"{slug}_balance_sheet_{freq}.csv\"\n",
    "    is_path = data_dir / f\"{slug}_income_statement_{freq}.csv\"\n",
    "\n",
    "    if bs_path.exists() and is_path.exists():\n",
    "        bs = _load_cached(bs_path)\n",
    "        is_df = _load_cached(is_path)\n",
    "\n",
    "    else:\n",
    "        tkr = yf.Ticker(ticker)\n",
    "        bs, is_df = _fetch_statements(tkr, freq)\n",
    "\n",
    "        if not bs.empty and not is_df.empty:\n",
    "            bs.to_csv(bs_path)\n",
    "            is_df.to_csv(is_path)\n",
    "\n",
    "    if bs.empty or is_df.empty:\n",
    "\n",
    "        raise RuntimeError(f\"Failed to fetch statements for {ticker} ({freq})\")\n",
    "\n",
    "    bs = canonicalize_bs(bs)\n",
    "\n",
    "\n",
    "    return bs, is_df, freq\n",
    "\n",
    "\n",
    "TICKERS = [\n",
    "    \"AAPL\", \"GOOG\", \"700\", \"1810\", \"IBM\", \"TSLA\",\n",
    "    \"9633\", \"9987\", \"9988\", \"IBKR\", \"KO\", \"MCD\",\n",
    "    \"EL\", \"BRK B\", \"NESN\"\n",
    "]\n",
    "\n",
    "PRIMARY_TICKER = TICKERS[0]\n",
    "bs, is_df, stmt_freq = load_statements(PRIMARY_TICKER, freq = TARGET_FREQ)\n",
    "\n",
    "\n",
    "print(\"Loaded tickers:\", [normalize_ticker(t) for t in TICKERS])\n",
    "print(\"Statement frequency:\", stmt_freq)\n",
    "print(\"Balance sheet shape:\", bs.shape)\n",
    "print(\"Income statement shape:\", is_df.shape)\n",
    "print(\"Identity residual stats:\", summarize_identity(identity_residual(bs)))\n",
    "bs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f580ccd",
   "metadata": {},
   "source": [
    "## 2. Features & Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac2566b",
   "metadata": {},
   "source": [
    "### 2.1 Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d75430",
   "metadata": {},
   "source": [
    "#### 2.1.1 Derived Drivers (DSO/DPO/DIH, Margins, Growth, Logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8aef296",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _pick(df: pd.DataFrame, options):\n",
    "    \"\"\"Pick the first available series from the provided options.\"\"\"\n",
    "\n",
    "    for c in options:\n",
    "\n",
    "        if c in df.columns:\n",
    "\n",
    "            return df[c]\n",
    "\n",
    "    raise KeyError(f'Missing columns: {options}')\n",
    "\n",
    "\n",
    "def compute_features(bs: pd.DataFrame, is_df: pd.DataFrame, days: float = 365.0, growth_periods: int = 1) -> pd.DataFrame:\n",
    "    \"\"\"Compute financial ratios and growth features.\"\"\"\n",
    "\n",
    "    rev = _pick(is_df, ['Total Revenue', 'Operating Revenue', 'TotalRevenue', 'OperatingRevenue', 'Revenues'])\n",
    "    cogs = _pick(is_df, ['Cost Of Revenue', 'Cost of Revenue', 'CostOfRevenue', 'ReconciledCostOfRevenue'])\n",
    "    op_inc = _pick(is_df, ['Operating Income', 'OperatingIncome'])\n",
    "    net_inc = _pick(is_df, ['Net Income', 'NetIncome', 'NetIncomeFromContinuingOperationNetMinorityInterest'])\n",
    "    ar = _pick(bs, ['Accounts Receivable', 'AccountsReceivable'])\n",
    "    ap = _pick(bs, ['Accounts Payable', 'AccountsPayable'])\n",
    "    inv = _pick(bs, ['Inventory', 'Inventories'])\n",
    "\n",
    "    feats = pd.DataFrame(index = bs.index)\n",
    "\n",
    "    sales_per_day = rev / days\n",
    "    cogs_per_day = cogs / days\n",
    "\n",
    "    feats['dso'] = ar / sales_per_day\n",
    "    feats['dpo'] = ap / cogs_per_day\n",
    "    feats['dih'] = inv / cogs_per_day\n",
    "    feats['gross_margin'] = (rev - cogs) / rev\n",
    "    feats['op_margin'] = op_inc / rev\n",
    "    feats['net_margin'] = net_inc / rev\n",
    "    feats['rev_yoy'] = rev.pct_change(periods = growth_periods)\n",
    "    feats['cogs_yoy'] = cogs.pct_change(periods = growth_periods)\n",
    "    feats['netinc_yoy'] = net_inc.pct_change(periods = growth_periods)\n",
    "    feats['log_rev'] = np.log1p(rev)\n",
    "    feats['log_assets'] = np.log1p(_pick(bs, ['Total Assets', 'TotalAssets']))\n",
    "    \n",
    "    feats = feats.replace([np.inf, -np.inf], np.nan)\n",
    "    feats = feats.sort_index().ffill().bfill()\n",
    "\n",
    "\n",
    "    return feats\n",
    "\n",
    "\n",
    "period_days = 365.0 if TARGET_FREQ == 'yearly' else 90.0\n",
    "growth_periods = 1 if TARGET_FREQ == 'yearly' else 4\n",
    "\n",
    "features = compute_features(bs, is_df, days = period_days, growth_periods = growth_periods)\n",
    "features.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7191913",
   "metadata": {},
   "source": [
    "### 2.2 Dataset Assembly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c7aeaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_BS = ['Total Assets', 'Total Liabilities', 'Total Equity']\n",
    "TARGET_LE = ['Total Liabilities', 'Total Equity']\n",
    "NET_INCOME_COL = 'Net Income'\n",
    "STATE_COLS = [\n",
    "    'Accounts Receivable', 'Accounts Payable', 'Inventory', 'Net PPE',\n",
    "    'Total Liabilities', 'Total Equity', 'Retained Earnings'\n",
    "]\n",
    "\n",
    "\n",
    "def _has_any(df: pd.DataFrame, options: list[str]) -> bool:\n",
    "    \"\"\"Return True if any candidate column exists.\"\"\"\n",
    "\n",
    "    return any(c in df.columns for c in options)\n",
    "\n",
    "\n",
    "def missing_required_columns(bs: pd.DataFrame, is_df: pd.DataFrame) -> list[str]:\n",
    "    \"\"\"Return missing required columns for BS and IS.\"\"\"\n",
    "\n",
    "    missing = []\n",
    "\n",
    "    if not _has_any(bs, ['Total Assets', 'TotalAssets']):\n",
    "        missing.append('Total Assets')\n",
    "    \n",
    "    if not _has_any(bs, ['Total Liabilities', 'Total Liabilities', 'TotalLiabilities', 'Total Liabilities Net Minority Interest', 'TotalLiabilitiesNetMinorityInterest']):\n",
    "        missing.append('Total Liabilities')\n",
    "    \n",
    "    if not _has_any(bs, ['Total Equity', 'Stockholders Equity', 'StockholdersEquity', 'Total Equity Gross Minority Interest', 'TotalEquityGrossMinorityInterest']):\n",
    "        missing.append('Total Equity')\n",
    "    \n",
    "    if not _has_any(bs, ['Accounts Receivable', 'AccountsReceivable']):\n",
    "        missing.append('Accounts Receivable')\n",
    "    \n",
    "    if not _has_any(bs, ['Accounts Payable', 'AccountsPayable']):\n",
    "        missing.append('Accounts Payable')\n",
    "    \n",
    "    if not _has_any(bs, ['Inventory', 'Inventories']):\n",
    "        missing.append('Inventory')\n",
    "    \n",
    "    if not _has_any(bs, ['Net PPE', 'NetPPE']):\n",
    "        missing.append('Net PPE')\n",
    "    \n",
    "    if not _has_any(bs, ['Retained Earnings', 'RetainedEarnings']):\n",
    "        missing.append('Retained Earnings')\n",
    "\n",
    "    if not _has_any(is_df, ['Total Revenue', 'Operating Revenue', 'TotalRevenue', 'OperatingRevenue', 'Revenues']):\n",
    "        missing.append('Total Revenue')\n",
    "   \n",
    "    if not _has_any(is_df, ['Cost Of Revenue', 'Cost of Revenue', 'CostOfRevenue', 'ReconciledCostOfRevenue']):\n",
    "        missing.append('Cost Of Revenue')\n",
    "    \n",
    "    if not _has_any(is_df, ['Operating Income', 'OperatingIncome']):\n",
    "        missing.append('Operating Income')\n",
    "    \n",
    "    if not _has_any(is_df, ['Net Income', 'NetIncome', 'NetIncomeFromContinuingOperationNetMinorityInterest']):\n",
    "        missing.append('Net Income')\n",
    "\n",
    "\n",
    "    return missing\n",
    "\n",
    "\n",
    "def build_aligned_for_ticker(ticker: str) -> pd.DataFrame:\n",
    "    \"\"\"Build an aligned dataset for one ticker.\"\"\"\n",
    "\n",
    "    bs, is_df, freq = load_statements(ticker, freq = TARGET_FREQ)\n",
    "    missing = missing_required_columns(bs, is_df)\n",
    "    \n",
    "    if missing:\n",
    "\n",
    "        print(f\"{ticker}: skip, missing {missing}\")\n",
    "\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    period_days = 365.0 if freq == 'yearly' else 90.0\n",
    "    growth_periods = 1 if freq == 'yearly' else 4\n",
    "\n",
    "    features = compute_features(bs, is_df, days = period_days, growth_periods = growth_periods)\n",
    "    targets = bs[TARGET_BS].copy()\n",
    "    net_income = _pick(is_df, ['Net Income', 'NetIncome', 'NetIncomeFromContinuingOperationNetMinorityInterest']).rename(NET_INCOME_COL)\n",
    "    net_income = net_income.reindex(targets.index)\n",
    "\n",
    "    # Align features, targets, and net income on shared dates.\n",
    "    dataset = features.join(targets, how = 'inner').join(net_income, how = 'inner')\n",
    "    dataset = dataset.dropna()\n",
    "\n",
    "    rev_series = _pick(is_df, ['Total Revenue', 'Operating Revenue', 'TotalRevenue', 'OperatingRevenue', 'Revenues'])\n",
    "    # Shift state variables to create t-1 inputs.\n",
    "    prev_state_df = bs.reindex(columns = STATE_COLS).shift(1)\n",
    "    prev_state_df.columns = [f'prev_{c}' for c in STATE_COLS]\n",
    "    prev_state_df['prev_Total Revenue'] = rev_series.reindex(targets.index).shift(1)\n",
    "\n",
    "    # Combine current data with lagged state for modeling.\n",
    "    aligned = dataset.join(prev_state_df, how = 'inner').dropna()\n",
    "    aligned['ticker'] = ticker\n",
    "    aligned['stmt_freq'] = freq\n",
    "\n",
    "\n",
    "    return aligned\n",
    "\n",
    "\n",
    "aligned_list = []\n",
    "\n",
    "for ticker in [normalize_ticker(t) for t in TICKERS]:\n",
    "\n",
    "    try:\n",
    "        aligned_t = build_aligned_for_ticker(ticker)\n",
    "\n",
    "        if aligned_t.empty:\n",
    "\n",
    "            print(f\"{ticker}: empty after alignment\")\n",
    "\n",
    "        else:\n",
    "\n",
    "            print(f\"{ticker}: aligned rows = {aligned_t.shape[0]}\")\n",
    "            aligned_list.append(aligned_t)\n",
    "\n",
    "    except Exception as exc:\n",
    "\n",
    "        print(f\"{ticker}: failed ({exc})\")\n",
    "\n",
    "if not aligned_list:\n",
    "\n",
    "    raise RuntimeError('No aligned data available')\n",
    "\n",
    "aligned = pd.concat(aligned_list, axis = 0).sort_index()\n",
    "prev_cols = [f'prev_{c}' for c in STATE_COLS] + ['prev_Total Revenue']\n",
    "drop_cols = TARGET_BS + [NET_INCOME_COL] + prev_cols + ['ticker', 'stmt_freq']\n",
    "FEATURE_COLS = [c for c in aligned.columns if c not in drop_cols]\n",
    "\n",
    "\n",
    "print('Dataset shape:', aligned.shape)\n",
    "print('Feature cols:', len(FEATURE_COLS), 'Target cols:', len(TARGET_LE) + 1)\n",
    "print('Tickers:', aligned['ticker'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751f495f",
   "metadata": {},
   "source": [
    "### 2.3 Prev-state Matrix for Algebraic Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0979f5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_feat = aligned[FEATURE_COLS].values.astype('float32')\n",
    "Y_bs = aligned[TARGET_LE].values.astype('float32')\n",
    "Y_earn = aligned[[NET_INCOME_COL]].values.astype('float32')\n",
    "X_prev = aligned[prev_cols].values.astype('float32')\n",
    "\n",
    "\n",
    "print('Aligned shapes:', X_feat.shape, X_prev.shape, Y_bs.shape, Y_earn.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eff5de3",
   "metadata": {},
   "source": [
    "### 2.4 Scaling (z-score) for Stability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbb7c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_scaler = StandardScaler()\n",
    "bs_scaler = StandardScaler()\n",
    "earn_scaler = StandardScaler()\n",
    "prev_scaler = StandardScaler()\n",
    "\n",
    "X_feat_scaled = feat_scaler.fit_transform(X_feat)\n",
    "Y_bs_scaled = bs_scaler.fit_transform(Y_bs)\n",
    "Y_earn_scaled = earn_scaler.fit_transform(Y_earn)\n",
    "X_prev_scaled = prev_scaler.fit_transform(X_prev)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3badfb3a",
   "metadata": {},
   "source": [
    "### 2.5 Train/Val Split on Scaled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511f37a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = X_feat_scaled.shape[0]\n",
    "train_size = max(1, int(0.8 * n))\n",
    "\n",
    "X_train_feat = X_feat_scaled[:train_size]\n",
    "Y_train_bs = Y_bs_scaled[:train_size]\n",
    "Y_train_earn = Y_earn_scaled[:train_size]\n",
    "X_train_prev = X_prev_scaled[:train_size]\n",
    "\n",
    "X_val_feat = X_feat_scaled[train_size:] if train_size < n else X_feat_scaled[train_size - 1:]\n",
    "Y_val_bs = Y_bs_scaled[train_size:] if train_size < n else Y_bs_scaled[train_size - 1:]\n",
    "Y_val_earn = Y_earn_scaled[train_size:] if train_size < n else Y_earn_scaled[train_size - 1:]\n",
    "X_val_prev = X_prev_scaled[train_size:] if train_size < n else X_prev_scaled[train_size - 1:]\n",
    "\n",
    "\n",
    "print('Scaled train:', X_train_feat.shape, Y_train_bs.shape, Y_train_earn.shape)\n",
    "print('Scaled val:', X_val_feat.shape, Y_val_bs.shape, Y_val_earn.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d43e051",
   "metadata": {},
   "source": [
    "## 3. TensorFlow (Pareja/Pelaez Constrained)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bad65ce",
   "metadata": {},
   "source": [
    "### 3.1 TF Model with Algebraic Generator + Earnings Head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c449ad68",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlgebraicBS(keras.layers.Layer):\n",
    "    \"\"\"Layer that enforces algebraic balance sheet constraints.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize sublayers for balance sheet generation.\"\"\"\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.hidden = keras.layers.Dense(64, activation = 'relu')\n",
    "        self.rev_head = keras.layers.Dense(1, activation = 'relu')\n",
    "        self.cogs_head = keras.layers.Dense(1, activation = 'relu')\n",
    "        self.drivers = keras.layers.Dense(5)\n",
    "        self.margin_head = keras.layers.Dense(1)\n",
    "        self.payout_head = keras.layers.Dense(1)\n",
    "        self.earn_head = keras.layers.Dense(1, name = 'net_income_head')\n",
    "\n",
    "\n",
    "    def call(self, inputs: Tuple[tf.Tensor, tf.Tensor]):\n",
    "        \"\"\"Compute constrained balance sheet and earnings outputs.\"\"\"\n",
    "\n",
    "        if not isinstance(inputs, (tuple, list)):\n",
    "\n",
    "            raise TypeError(\"inputs must be (features, prev_state)\")\n",
    "\n",
    "        features, prev_state = inputs\n",
    "        ar_prev, ap_prev, inv_prev, ppe_prev, liab_prev, equity_prev, re_prev, rev_prev = tf.split(prev_state, num_or_size_splits = 8, axis = -1)\n",
    "        hidden = self.hidden(features)\n",
    "        rev_predicate = self.rev_head(hidden)\n",
    "        cogs_predicate = self.cogs_head(hidden)\n",
    "        drivers_raw = self.drivers(hidden)\n",
    "\n",
    "        dso = tf.nn.softplus(drivers_raw[:, 0:1])\n",
    "        dpo = tf.nn.softplus(drivers_raw[:, 1:2])\n",
    "        dih = tf.nn.softplus(drivers_raw[:, 2:3])\n",
    "        dep_rate = tf.nn.sigmoid(drivers_raw[:, 3:4]) * 0.2\n",
    "        capex_rate = tf.nn.sigmoid(drivers_raw[:, 4:5]) * 0.2\n",
    "        net_margin = tf.tanh(self.margin_head(hidden)) * 0.5\n",
    "        div_payout = tf.nn.sigmoid(self.payout_head(hidden))\n",
    "\n",
    "        sales_per_day = rev_predicate / 365.0\n",
    "        cogs_per_day = cogs_predicate / 365.0\n",
    "\n",
    "        ar_next = dso * sales_per_day\n",
    "        ap_next = dpo * cogs_per_day\n",
    "        inv_next = dih * cogs_per_day\n",
    "        dep = dep_rate * ppe_prev\n",
    "        capex = capex_rate * rev_predicate\n",
    "        ppe_next = ppe_prev + capex - dep\n",
    "        net_income = net_margin * rev_predicate\n",
    "        earn_predicate = self.earn_head(hidden)\n",
    "        div = div_payout * net_income\n",
    "        re_next = re_prev + net_income - div\n",
    "\n",
    "        other_equity = tf.nn.relu(equity_prev - re_prev)\n",
    "\n",
    "        equity_next = re_next + other_equity\n",
    "\n",
    "        other_liab_prev = tf.nn.relu(liab_prev - ap_prev)\n",
    "        growth = tf.where(rev_prev > 0, rev_predicate / rev_prev - 1.0, tf.zeros_like(rev_predicate))\n",
    "\n",
    "        other_liab_next = other_liab_prev * (1.0 + growth)\n",
    "        liab_next = ap_next + other_liab_next\n",
    "        assets_wo_cash = ar_next + inv_next + ppe_next\n",
    "        cash_next = equity_next + liab_next - assets_wo_cash\n",
    "        assets_next = liab_next + equity_next\n",
    "        bs_out = tf.concat([liab_next, equity_next], axis = -1)\n",
    "\n",
    "\n",
    "        return bs_out, earn_predicate\n",
    "\n",
    "\n",
    "def build_pareja_model(feat_dim: int, state_dim: int = 8):\n",
    "    \"\"\"Build a Pareja/Pelaez-constrained model.\"\"\"\n",
    "\n",
    "    feat_in = keras.Input(shape = (feat_dim,), name = 'features')\n",
    "    state_in = keras.Input(shape = (state_dim,), name = 'prev_state')\n",
    "    bs_out, earn_out = AlgebraicBS()([feat_in, state_in])\n",
    "    \n",
    "    \n",
    "    return keras.Model([feat_in, state_in], [bs_out, earn_out], name = 'bs_pareja_style')\n",
    "\n",
    "\n",
    "pareja_model = build_pareja_model(feat_dim = X_feat_scaled.shape[1], state_dim = X_prev_scaled.shape[1])\n",
    "pareja_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77598143",
   "metadata": {},
   "source": [
    "### 3.2 Train/Evaluate (MAE on BS + Earnings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e0bafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "pareja_model.compile(\n",
    "    optimizer = keras.optimizers.Adam(1e-3),\n",
    "    loss = [keras.losses.MeanAbsoluteError(), keras.losses.MeanAbsoluteError()],\n",
    "    loss_weights = [1.0, 0.3],\n",
    ")\n",
    "\n",
    "hist = pareja_model.fit(\n",
    "    [X_train_feat, X_train_prev], [Y_train_bs, Y_train_earn],\n",
    "    \n",
    "    validation_data = (\n",
    "        [X_val_feat, X_val_prev], [Y_val_bs, Y_val_earn]\n",
    "    ) if len(X_val_feat) > 0 else None,\n",
    "    \n",
    "    epochs = 20,\n",
    "    batch_size = 2,\n",
    "    verbose = 0,\n",
    ")\n",
    "\n",
    "\n",
    "print('Final Train Losses:', '\\n', {k: v[-1] for k, v in hist.history.items() if 'loss' in k}, '\\n')\n",
    "\n",
    "bs_predicate_scaled, earn_predicate_scaled = pareja_model.predict([X_feat_scaled, X_prev_scaled], verbose = 0)\n",
    "bs_predicate = bs_scaler.inverse_transform(bs_predicate_scaled)\n",
    "earn_predicate = earn_scaler.inverse_transform(earn_predicate_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a400bdc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs_predicate_df = pd.DataFrame(bs_predicate, columns = TARGET_LE, index = aligned.index)\n",
    "assets_predicate = bs_predicate_df['Total Liabilities'] + bs_predicate_df['Total Equity']\n",
    "bs_predicate_full = bs_predicate_df.copy()\n",
    "bs_predicate_full['Total Assets'] = assets_predicate\n",
    "bs_predicate_full = bs_predicate_full[TARGET_BS]\n",
    "resid_predicate = bs_predicate_full['Total Assets'] - (bs_predicate_full['Total Liabilities'] + bs_predicate_full['Total Equity'])\n",
    "\n",
    "pred_full = bs_predicate_full.copy()\n",
    "pred_full['ticker'] = aligned['ticker'].values\n",
    "pred_full['stmt_freq'] = aligned['stmt_freq'].values\n",
    "pred_full['pred_net_income'] = earn_predicate.flatten()\n",
    "pred_full['pred_resid'] = pred_full['Total Assets'] - (pred_full['Total Liabilities'] + pred_full['Total Equity'])\n",
    "\n",
    "actual_bs = aligned[TARGET_BS].copy()\n",
    "actual_bs.columns = [f'actual_{c}' for c in actual_bs.columns]\n",
    "pred_full = pd.concat([pred_full, actual_bs], axis = 1)\n",
    "pred_full['actual_net_income'] = aligned[NET_INCOME_COL].values\n",
    "\n",
    "pred_full['err_assets'] = pred_full['Total Assets'] - pred_full['actual_Total Assets']\n",
    "pred_full['err_liab'] = pred_full['Total Liabilities'] - pred_full['actual_Total Liabilities']\n",
    "pred_full['err_equity'] = pred_full['Total Equity'] - pred_full['actual_Total Equity']\n",
    "pred_full['err_net_income'] = pred_full['pred_net_income'] - pred_full['actual_net_income']\n",
    "pred_full['abs_err_assets'] = pred_full['err_assets'].abs()\n",
    "pred_full['abs_err_liab'] = pred_full['err_liab'].abs()\n",
    "pred_full['abs_err_equity'] = pred_full['err_equity'].abs()\n",
    "pred_full['abs_err_net_income'] = pred_full['err_net_income'].abs()\n",
    "\n",
    "summary = pred_full.groupby('ticker').agg(\n",
    "    samples = ('pred_net_income', 'size'),\n",
    "    mean_pred_assets = ('Total Assets', 'mean'),\n",
    "    mean_pred_liab = ('Total Liabilities', 'mean'),\n",
    "    mean_pred_equity = ('Total Equity', 'mean'),\n",
    "    mean_pred_net_income = ('pred_net_income', 'mean'),\n",
    "    mean_actual_assets = ('actual_Total Assets', 'mean'),\n",
    "    mean_actual_liab = ('actual_Total Liabilities', 'mean'),\n",
    "    mean_actual_equity = ('actual_Total Equity', 'mean'),\n",
    "    mean_actual_net_income = ('actual_net_income', 'mean'),\n",
    "    mae_assets = ('abs_err_assets', 'mean'),\n",
    "    mae_liab = ('abs_err_liab', 'mean'),\n",
    "    mae_equity = ('abs_err_equity', 'mean'),\n",
    "    mae_net_income = ('abs_err_net_income', 'mean'),\n",
    ")\n",
    "\n",
    "def format_df_for_view(df: pd.DataFrame, decimals: int = 2) -> pd.DataFrame:\n",
    "    \"\"\"Create a display-only view with formatted numerics.\"\"\"\n",
    "\n",
    "    view = df.copy()\n",
    "    num_cols = view.select_dtypes(include = [np.number]).columns\n",
    "    fmt = f\"{{:,.{decimals}f}}\"\n",
    "    view[num_cols] = view[num_cols].map(lambda v: \"\" if pd.isna(v) else fmt.format(v))\n",
    "\n",
    "    return view\n",
    "\n",
    "\n",
    "bs_predicate_full_view = format_df_for_view(bs_predicate_full)\n",
    "pred_full_view = format_df_for_view(pred_full)\n",
    "summary_view = format_df_for_view(summary)\n",
    "\n",
    "earn_head_str = np.array2string(\n",
    "    earn_predicate.flatten(),\n",
    "    formatter = {\"float_kind\": lambda v: f\"{v:,.2f}\"}\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
